{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification Across Two Mammography Datasets\n",
    "\n",
    "## Authors\n",
    "\n",
    "Maximilian Dieringer (h12314676)                      \n",
    "Harald Körbel (h12208935)\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook analyzes how two deep learning models for breast cancer classification perform when applied across two different mammography datasets.\n",
    "We investigate two central aspects:\n",
    "\n",
    "- Domain shift: how a model trained on the RSNA dataset behaves when evaluated on KAU                                     \n",
    "- Catastrophic forgetting: how performance on RSNA changes after fine tuning on KAU\n",
    "\n",
    "Our goal is to compare two widely used convolutional neural network architectures and understand their robustness across datasets.\n",
    "\n",
    "## Motivation for the Project\n",
    "\n",
    "Our motivation for this project is deeply personal. Having witnessed cases of breast cancer within our immediate surroundings, we wanted to engage with this topic on a deeper level and explore how effectively machine learning models can assist in detecting breast cancer from medical images. This project was not only an opportunity to work on a problem that directly affects and interests us, but also a chance to contribute to something with potential real-world impact.\n",
    "\n",
    "Additionally, the idea of working with image-based input data was particularly compelling for us. The combination of personal relevance, scientific curiosity, and the challenge of applying deep learning techniques to medical imaging made this project especially meaningful.\n",
    "\n",
    "## Base Model\n",
    "\n",
    "**EfficientNet-B0 Breast Cancer Classification (Hugging Face)**                                    \n",
    "https://huggingface.co/keanteng/efficientnet-b0-breast-cancer-classification-0604-2\n",
    "\n",
    "Key characteristics:\n",
    "- EfficientNet-B0 architecture  \n",
    "- Pretrained on ImageNet  \n",
    "- Fine tuned on the Mini-DDBS-JPEG mammography dataset  \n",
    "- Input size: 256×256  \n",
    "- Binary labels: Has_Cancer (1) vs Normal (0)\n",
    "\n",
    "**ResNet-50 (Torchvision)**                                \n",
    "https://huggingface.co/microsoft/resnet-50\n",
    "\n",
    "Key characteristics:\n",
    "- ResNet-50 architecture with residual connections\n",
    "- Pretrained on ImageNet\n",
    "- Widely used as a strong and stable baseline for medical imaging\n",
    "- Default input size 224×224 (we upscale to 256×256 for consistency)\n",
    "- Binary classification head adapted for Cancer vs No Cancer prediction\n",
    "\n",
    "## Datasets\n",
    "\n",
    "- **Dataset 1: RSNA Screening Mammography**  \n",
    "    Used for: baseline inference, fine tuning, evaluation  \n",
    "    https://www.kaggle.com/datasets/theoviel/rsna-breast-cancer-256-pngs\n",
    "\n",
    "- **Dataset 2: KAU-BCMD Mammography**  \n",
    "    Used for: zero-shot inference, fine tuning, evaluation  \n",
    "    https://www.kaggle.com/datasets/orvile/kau-bcmd-mamography-dataset\n",
    "\n",
    "Both datasets allow creating a consistent binary cancer label.\n",
    "\n",
    "## Notebook Workflow Overview\n",
    "\n",
    "This notebook is structured into four main parts:\n",
    "\n",
    "- **Part 1: Shared Setup and Data Pipeline**  \n",
    "  Data loading, preprocessing, splitting, transforms, dataloaders, and all shared utilities used by both models.\n",
    "\n",
    "- **Part 2: EfficientNet-B0 Pipeline**  \n",
    "  Full training workflow for EfficientNet-B0, including baseline, fine-tuning on RSNA and KAU, and back-evaluation.\n",
    "\n",
    "- **Part 3: ResNet-50 Pipeline**  \n",
    "  Identical workflow applied to ResNet-50 to enable a controlled architecture comparison.\n",
    "\n",
    "- **Part 4: Final Cross-Model Comparison**  \n",
    "  Finally we compare the Models from Part 2 & 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "# Part 1: Shared Setup and Data Pipeline\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "1.1 Import libraries  \n",
    "1.2 Configure global settings and file paths  \n",
    "1.3 Define hyperparameters  \n",
    "\n",
    "\n",
    "## 2. Data Preparation\n",
    "\n",
    "2.1 RSNA: load and clean metadata  \n",
    "2.2 RSNA: split and save stratified CSV files  \n",
    "2.3 KAU: load and clean metadata  \n",
    "2.4 KAU: split and save stratified CSV files  \n",
    "\n",
    "\n",
    "## 3. Shared Utilities\n",
    "\n",
    "3.1 Dataset class for CSV-based image loading  \n",
    "3.2 Image transforms (train, validation, test)  \n",
    "3.3 Helper functions for metrics  \n",
    "3.4 Training and evaluation functions  \n",
    "3.5 Function to load EfficientNet-B0 model  \n",
    "3.6 Function to load ResNet-50 model  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1 Import libraries\n",
    "\n",
    "We import all core libraries used throughout the project:\n",
    "\n",
    "- **pathlib / json**: file paths and config handling  \n",
    "- **pandas**: handling CSV files  \n",
    "- **torch / torchvision**: deep learning framework and image handling  \n",
    "- **sklearn**: train/val/test splitting and metrics  \n",
    "- **PIL**: image loading  \n",
    "- **huggingface_hub**: downloading pretrained models\n",
    "- **matplotlib**: plotting graphs  \n",
    "\n",
    "This ensures that all later notebook sections have the required dependencies ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Import libraries\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "from PIL import Image\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file as safe_load\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select device: use GPU if available, otherwise CPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configure global settings and file paths\n",
    "\n",
    "We define:\n",
    "\n",
    "- root directories for RSNA images and metadata (train.csv)  \n",
    "- dedicated output directories for saving train/val/test CSV splits for **RSNA** and **KAU**  \n",
    "- global constants such as test/validation split fractions and the random seed  \n",
    "- backwards-compatible aliases (`IMAGES_DIR`, `LABELS_CSV_PATH`, `OUTPUT_DIR`) so existing code keeps working\n",
    "\n",
    "This creates a consistent file structure so all remaining stages can load data reliably.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Configure global settings and file paths\n",
    "\n",
    "# RSNA image directory (Theo Viel 256×256 PNGs)\n",
    "RSNA_IMAGES_DIR = Path(\"/kaggle/input/rsna-breast-cancer-256-pngs\")\n",
    "\n",
    "# RSNA labels (original competition train.csv)\n",
    "RSNA_LABELS_CSV_PATH = Path(\"/kaggle/input/rsna-breast-cancer-detection/train.csv\")\n",
    "\n",
    "# Where we will store the train/val/test CSV splits for RSNA\n",
    "RSNA_SPLITS_DIR = Path(\"/kaggle/working/rsna_splits\")\n",
    "RSNA_SPLITS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Where we will store the train/val/test CSV splits for KAU\n",
    "KAU_SPLITS_DIR = Path(\"/kaggle/working/kau_splits\")\n",
    "KAU_SPLITS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Fractions for splitting the data\n",
    "TEST_FRACTION = 0.25                 # 25% of all data for test\n",
    "VAL_FRACTION_WITHIN_TRAINVAL = 0.20  # 20% of the remaining 75% → 15% of total as validation\n",
    "RANDOM_STATE = 42                    # for reproducible splits\n",
    "\n",
    "print(\"RSNA_IMAGES_DIR:\", RSNA_IMAGES_DIR)\n",
    "print(\"RSNA_LABELS_CSV_PATH:\", RSNA_LABELS_CSV_PATH)\n",
    "print(\"RSNA_SPLITS_DIR:\", RSNA_SPLITS_DIR)\n",
    "print(\"KAU_SPLITS_DIR:\", KAU_SPLITS_DIR)\n",
    "print(\"TEST_FRACTION:\", TEST_FRACTION)\n",
    "print(\"VAL_FRACTION_WITHIN_TRAINVAL:\", VAL_FRACTION_WITHIN_TRAINVAL)\n",
    "print(\"RANDOM_STATE:\", RANDOM_STATE)\n",
    "\n",
    "# Backwards compatible aliases so existing code below keeps working\n",
    "IMAGES_DIR      = RSNA_IMAGES_DIR\n",
    "LABELS_CSV_PATH = RSNA_LABELS_CSV_PATH\n",
    "OUTPUT_DIR      = RSNA_SPLITS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define hyperparameters\n",
    "\n",
    "We set the training hyperparameters that will be used across all fine-tuning stages:\n",
    "\n",
    "- batch size  \n",
    "- number of DataLoader workers  \n",
    "- learning rate and weight decay  \n",
    "- number of epochs for RSNA (Model 1)  \n",
    "- number of epochs for KAU (Model 2)\n",
    "\n",
    "These parameters ensure that all fine-tuned variants of the base models are trained with consistent settings across stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Define hyperparameters\n",
    "\n",
    "# Shared across all training stages\n",
    "BATCH_SIZE  = 16          # number of images per batch\n",
    "NUM_WORKERS = 2           # number of worker processes for data loading\n",
    "\n",
    "LEARNING_RATE = 3e-5      # learning rate for AdamW optimizer\n",
    "WEIGHT_DECAY  = 5e-4      # L2 regularization to reduce overfitting\n",
    "\n",
    "# Number of training epochs per stage\n",
    "NUM_EPOCHS_RSNA = 30      # epochs for fine tuning on RSNA (Model 1)\n",
    "NUM_EPOCHS_KAU  = 10      # epochs for fine tuning on KAU (Model 2)\n",
    "\n",
    "print(\"BATCH_SIZE:\", BATCH_SIZE)\n",
    "print(\"NUM_WORKERS:\", NUM_WORKERS)\n",
    "print(\"LEARNING_RATE:\", LEARNING_RATE)\n",
    "print(\"WEIGHT_DECAY:\", WEIGHT_DECAY)\n",
    "print(\"NUM_EPOCHS_RSNA:\", NUM_EPOCHS_RSNA)\n",
    "print(\"NUM_EPOCHS_KAU:\", NUM_EPOCHS_KAU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "### 2.1 RSNA: load and clean metadata\n",
    "\n",
    "We load the original RSNA metadata (train.csv) and perform:\n",
    "\n",
    "- column selection (patient_id, image_id, cancer)  \n",
    "- removal of duplicates  \n",
    "- construction of PNG filenames  \n",
    "- creation of absolute image paths  \n",
    "- filtering for existing image files  \n",
    "- adding a dataset identifier column (`dataset_source = \"RSNA\"`)  \n",
    "- a quick sanity check of the class distribution after filtering  \n",
    "\n",
    "This results in a clean DataFrame where each row corresponds to one real RSNA image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 RSNA: load and clean metadata\n",
    "\n",
    "# Load original RSNA train.csv with labels\n",
    "rsna_labels = pd.read_csv(RSNA_LABELS_CSV_PATH)\n",
    "print(\"RSNA train.csv loaded, number of rows:\", len(rsna_labels))\n",
    "display(rsna_labels.head())\n",
    "\n",
    "# Keep only the columns we actually need and remove duplicate rows\n",
    "rsna_labels = rsna_labels[[\"patient_id\", \"image_id\", \"cancer\"]].drop_duplicates(\n",
    "    subset=[\"patient_id\", \"image_id\"]\n",
    ")\n",
    "print(\"\\nAfter selecting columns and dropping duplicates:\")\n",
    "display(rsna_labels.head())\n",
    "print(\"Number of unique image entries:\", len(rsna_labels))\n",
    "\n",
    "# Helper function: build the PNG file name for each row\n",
    "def make_rsna_filename(row):\n",
    "    \"\"\"Create the PNG filename for a given RSNA row.\"\"\"\n",
    "    return f\"{row['patient_id']}_{row['image_id']}.png\"\n",
    "\n",
    "# Add filename column\n",
    "rsna_labels[\"filename\"] = rsna_labels.apply(make_rsna_filename, axis=1)\n",
    "\n",
    "# Add full path column (Theo Viel PNG dataset)\n",
    "rsna_labels[\"path\"] = rsna_labels[\"filename\"].apply(\n",
    "    lambda name: RSNA_IMAGES_DIR / name\n",
    ")\n",
    "\n",
    "# Keep only rows where the PNG file actually exists on disk\n",
    "rsna_labels[\"exists\"] = rsna_labels[\"path\"].apply(lambda p: p.exists())\n",
    "rsna_df = (\n",
    "    rsna_labels[rsna_labels[\"exists\"]]\n",
    "    .drop(columns=[\"exists\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Add a dataset identifier so we can later distinguish RSNA and KAU\n",
    "rsna_df[\"dataset_source\"] = \"RSNA\"\n",
    "\n",
    "print(\"\\nDataFrame after filtering for existing PNG files:\")\n",
    "display(rsna_df.head())\n",
    "print(\"Number of images with existing PNG files:\", len(rsna_df))\n",
    "\n",
    "# Quick sanity check of the class distribution after filtering\n",
    "print(\"\\nClass distribution in RSNA after filtering existing files:\")\n",
    "print(rsna_df[\"cancer\"].value_counts())\n",
    "print(rsna_df[\"cancer\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 RSNA: create and save stratified CSV files\n",
    "\n",
    "We now use the full RSNA dataset without any manual class balancing.  \n",
    "To obtain robust splits while preserving the original class ratio, we:\n",
    "\n",
    "- inspect the overall class distribution and ensure that both classes are present  \n",
    "- create a stratified split into train+val and test using `TEST_FRACTION`  \n",
    "- further split train+val into train and validation using a stratified split  \n",
    "- print class distributions (absolute and relative) for all three splits  \n",
    "- save the resulting train/val/test CSV files (patient_id, image_id, cancer, path, dataset_source) to `RSNA_SPLITS_DIR`  \n",
    "\n",
    "These CSVs serve as the unified RSNA dataset splits for all subsequent stages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 RSNA: split and save stratified CSV files\n",
    "\n",
    "# We now use the full RSNA dataset without manual balancing.\n",
    "# We only create stratified train / validation / test splits\n",
    "# so that each split reflects the original class distribution.\n",
    "\n",
    "rsna_for_split = rsna_df.copy()\n",
    "\n",
    "# Basic sanity check: we need at least two classes to stratify\n",
    "class_counts = rsna_for_split[\"cancer\"].value_counts()\n",
    "print(\"Class distribution in RSNA before splitting:\")\n",
    "print(class_counts)\n",
    "print(class_counts / class_counts.sum())\n",
    "\n",
    "if class_counts.shape[0] < 2:\n",
    "    raise ValueError(\"RSNA dataset must contain both positive and negative examples for stratified splits.\")\n",
    "\n",
    "print(\"\\nTotal number of RSNA images used for splits:\", len(rsna_for_split))\n",
    "\n",
    "# 1) Split into train+val and test\n",
    "trainval_df, test_df = train_test_split(\n",
    "    rsna_for_split,\n",
    "    test_size=TEST_FRACTION,          # e.g. 0.25 of all data for test\n",
    "    stratify=rsna_for_split[\"cancer\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(\"\\nSizes after first split (train+val vs. test):\")\n",
    "print(\"train+val:\", len(trainval_df))\n",
    "print(\"test:     \", len(test_df))\n",
    "\n",
    "# 2) Split train+val into train and val\n",
    "train_df, val_df = train_test_split(\n",
    "    trainval_df,\n",
    "    test_size=VAL_FRACTION_WITHIN_TRAINVAL,   # e.g. 0.20 of train+val becomes validation\n",
    "    stratify=trainval_df[\"cancer\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(\"\\nFinal split sizes:\")\n",
    "print(\"train:\", len(train_df))\n",
    "print(\"val:  \", len(val_df))\n",
    "print(\"test: \", len(test_df))\n",
    "\n",
    "print(\"\\nClass distribution in each split (absolute counts):\")\n",
    "print(\"Train:\\n\", train_df[\"cancer\"].value_counts())\n",
    "print(\"\\nVal:\\n\",   val_df[\"cancer\"].value_counts())\n",
    "print(\"\\nTest:\\n\",  test_df[\"cancer\"].value_counts())\n",
    "\n",
    "print(\"\\nClass distribution in each split (relative frequencies):\")\n",
    "print(\"Train:\\n\", train_df[\"cancer\"].value_counts(normalize=True))\n",
    "print(\"\\nVal:\\n\",   val_df[\"cancer\"].value_counts(normalize=True))\n",
    "print(\"\\nTest:\\n\",  test_df[\"cancer\"].value_counts(normalize=True))\n",
    "\n",
    "# Ensure the output directory exists\n",
    "RSNA_SPLITS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save splits as CSV (same columns as before so later code keeps working)\n",
    "cols_to_keep = [\"patient_id\", \"image_id\", \"cancer\", \"path\", \"dataset_source\"]\n",
    "\n",
    "for name, split_df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    out_path = RSNA_SPLITS_DIR / f\"{name}_split.csv\"\n",
    "    split_df[cols_to_keep].to_csv(out_path, index=False)\n",
    "    print(f\"\\n{name.upper()} split stored under: {out_path}\")\n",
    "\n",
    "print(\"\\nRSNA train/val/test splits with real class ratio are now ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 KAU: load and clean metadata\n",
    "\n",
    "We traverse the KAU dataset folder structure and automatically detect the folder that contains the BI-RADS subfolders. Then we:\n",
    "\n",
    "- read images from the BI-RADS folders `birads1`, `birads3`, `birads4`, `birads5`  \n",
    "- convert BI-RADS categories into binary cancer labels (1 → no cancer, 3/4/5 → cancer)  \n",
    "- store image IDs, full image paths, BI-RADS values, binary cancer labels, and a dataset identifier (`dataset_source = \"KAU\"`) in a DataFrame  \n",
    "- report the BI-RADS and cancer label distributions as a sanity check  \n",
    "\n",
    "This creates a consistent structure similar to the RSNA DataFrame (path + labels + dataset source).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 KAU: load and clean metadata\n",
    "\n",
    "# Root directory of the KAU BCMD dataset in the Kaggle environment\n",
    "KAU_ROOT_DIR = Path(\"/kaggle/input/kau-bcmd-mamography-dataset\")\n",
    "\n",
    "print(\"KAU root directory:\", KAU_ROOT_DIR)\n",
    "print(\"Contents of KAU root directory:\")\n",
    "for p in KAU_ROOT_DIR.iterdir():\n",
    "    print(\"  \", p.name)\n",
    "\n",
    "# In the Kaggle dataset the images are inside a folder that contains\n",
    "# subfolders like 'birads1', 'birads3', 'birads4', 'birads5'.\n",
    "# We search for the folder that actually contains these BI-RADS folders.\n",
    "potential_roots = [KAU_ROOT_DIR] + [p for p in KAU_ROOT_DIR.iterdir() if p.is_dir()]\n",
    "\n",
    "dataset_root = None\n",
    "for candidate in potential_roots:\n",
    "    birads1_dir = candidate / \"birads1\"\n",
    "    if birads1_dir.exists() and birads1_dir.is_dir():\n",
    "        dataset_root = candidate\n",
    "        break\n",
    "\n",
    "if dataset_root is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find a folder containing 'birads1' inside \"\n",
    "        f\"{KAU_ROOT_DIR}. Please check the dataset structure in Kaggle.\"\n",
    "    )\n",
    "\n",
    "print(\"\\nDetected KAU dataset root:\", dataset_root)\n",
    "\n",
    "# Mapping from folder names to BI-RADS value\n",
    "folder_to_birads = {\n",
    "    \"birads1\": 1,  # negative\n",
    "    \"birads3\": 3,  # probably benign\n",
    "    \"birads4\": 4,  # suspicious malignant\n",
    "    \"birads5\": 5,  # malignant\n",
    "}\n",
    "\n",
    "def birads_to_cancer(birads_value: int) -> int:\n",
    "    \"\"\"\n",
    "    Map a BI-RADS category to a binary cancer label.\n",
    "\n",
    "    BI-RADS 1 is treated as no cancer (0).\n",
    "    BI-RADS 3, 4 and 5 are treated as cancer (1).\n",
    "    \"\"\"\n",
    "    if birads_value in [1]:\n",
    "        return 0\n",
    "    elif birads_value in [3, 4, 5]:\n",
    "        return 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected BI-RADS value: {birads_value}\")\n",
    "\n",
    "# Collect image records from all BI-RADS folders\n",
    "records = []\n",
    "\n",
    "# We accept common image file extensions\n",
    "image_extensions = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"}\n",
    "\n",
    "for folder_name, birads_value in folder_to_birads.items():\n",
    "    folder_path = dataset_root / folder_name\n",
    "\n",
    "    if not folder_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Expected BI-RADS folder '{folder_name}' not found under {dataset_root}.\"\n",
    "        )\n",
    "\n",
    "    # Collect all image files in this BI-RADS folder (recursively)\n",
    "    image_files = [\n",
    "        p\n",
    "        for p in folder_path.rglob(\"*\")\n",
    "        if p.is_file() and p.suffix.lower() in image_extensions\n",
    "    ]\n",
    "\n",
    "    print(f\"Found {len(image_files)} files in folder {folder_name}.\")\n",
    "\n",
    "    for img_path in image_files:\n",
    "        image_id = img_path.stem\n",
    "        cancer_label = birads_to_cancer(birads_value)\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"image_id\": image_id,\n",
    "                \"path\": str(img_path),\n",
    "                \"birads\": birads_value,\n",
    "                \"cancer\": cancer_label,\n",
    "                \"dataset_source\": \"KAU\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Build DataFrame from all collected records\n",
    "kau_df = pd.DataFrame(records)\n",
    "\n",
    "print(\"\\nKAU DataFrame created.\")\n",
    "print(\"Shape (rows, columns):\", kau_df.shape)\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(kau_df.head())\n",
    "\n",
    "print(\"\\nBI-RADS value counts:\")\n",
    "print(kau_df[\"birads\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nCancer label value counts:\")\n",
    "print(kau_df[\"cancer\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 KAU: split and save stratified CSV files\n",
    "\n",
    "We now use the full KAU dataset without any manual class balancing.  \n",
    "To obtain robust splits while preserving the original class ratio, we:\n",
    "\n",
    "- inspect the overall class distribution and ensure both classes are present  \n",
    "- create a stratified split into train+val and test using the same `TEST_FRACTION` as for RSNA  \n",
    "- further split train+val into train and validation using a stratified split with `VAL_FRACTION_WITHIN_TRAINVAL`  \n",
    "- report class distributions (absolute and relative) for all three splits  \n",
    "- save the resulting train/val/test CSV files (e.g. `path`, `cancer`, `birads`, `dataset_source`) into the dedicated `KAU_SPLITS_DIR`  \n",
    "\n",
    "These CSVs allow us to reuse the same DataLoader and training pipeline as for RSNA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 KAU: split and save stratified CSV files\n",
    "\n",
    "# We now use the full KAU dataset without manual balancing.\n",
    "# We only create stratified train / validation / test splits\n",
    "# so that each split reflects the original class distribution.\n",
    "\n",
    "kau_for_split = kau_df.copy()\n",
    "\n",
    "# Basic sanity check: we need at least two classes to stratify\n",
    "class_counts_kau = kau_for_split[\"cancer\"].value_counts()\n",
    "print(\"Class distribution in KAU before splitting:\")\n",
    "print(class_counts_kau)\n",
    "print(class_counts_kau / class_counts_kau.sum())\n",
    "\n",
    "if class_counts_kau.shape[0] < 2:\n",
    "    raise ValueError(\"KAU dataset must contain both positive and negative examples for stratified splits.\")\n",
    "\n",
    "print(\"\\nTotal number of KAU images used for splits:\", len(kau_for_split))\n",
    "\n",
    "# 1) Split into train+val and test\n",
    "kau_trainval_df, kau_test_df = train_test_split(\n",
    "    kau_for_split,\n",
    "    test_size=TEST_FRACTION,           # same fraction as for RSNA\n",
    "    stratify=kau_for_split[\"cancer\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(\"\\nSizes after first split (train+val vs. test):\")\n",
    "print(\"train+val:\", len(kau_trainval_df))\n",
    "print(\"test:     \", len(kau_test_df))\n",
    "\n",
    "# 2) Split train+val into train and val\n",
    "kau_train_df, kau_val_df = train_test_split(\n",
    "    kau_trainval_df,\n",
    "    test_size=VAL_FRACTION_WITHIN_TRAINVAL,   # same relative validation size as for RSNA\n",
    "    stratify=kau_trainval_df[\"cancer\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(\"\\nFinal split sizes:\")\n",
    "print(\"train:\", len(kau_train_df))\n",
    "print(\"val:  \", len(kau_val_df))\n",
    "print(\"test: \", len(kau_test_df))\n",
    "\n",
    "print(\"\\nClass distribution in each split (absolute counts):\")\n",
    "print(\"Train:\\n\", kau_train_df[\"cancer\"].value_counts())\n",
    "print(\"\\nVal:\\n\",   kau_val_df[\"cancer\"].value_counts())\n",
    "print(\"\\nTest:\\n\",  kau_test_df[\"cancer\"].value_counts())\n",
    "\n",
    "print(\"\\nClass distribution in each split (relative frequencies):\")\n",
    "print(\"Train:\\n\", kau_train_df[\"cancer\"].value_counts(normalize=True))\n",
    "print(\"\\nVal:\\n\",   kau_val_df[\"cancer\"].value_counts(normalize=True))\n",
    "print(\"\\nTest:\\n\",  kau_test_df[\"cancer\"].value_counts(normalize=True))\n",
    "\n",
    "# Ensure the output directory exists\n",
    "KAU_SPLITS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save splits as CSV\n",
    "# We keep the same column structure that is already present in kau_df.\n",
    "# At minimum this includes \"path\" and \"cancer\"; often also \"birads\" and \"dataset_source\".\n",
    "cols_to_keep = [col for col in [\"path\", \"cancer\", \"birads\", \"dataset_source\"] if col in kau_for_split.columns]\n",
    "\n",
    "for name, split_df in [(\"train\", kau_train_df), (\"val\", kau_val_df), (\"test\", kau_test_df)]:\n",
    "    out_path = KAU_SPLITS_DIR / f\"{name}_split.csv\"\n",
    "    split_df[cols_to_keep].to_csv(out_path, index=False)\n",
    "    print(f\"\\n{name.upper()} split stored under: {out_path}\")\n",
    "\n",
    "print(\"\\nKAU train/val/test splits with real class ratio are now ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Shared utilities\n",
    "\n",
    "### 3.1 Dataset class for CSV-based image loading\n",
    "\n",
    "We use a single generic `CsvImageDataset` that reads image paths and labels from a CSV file.  \n",
    "This dataset works for both RSNA and KAU splits, as long as the CSV contains:\n",
    "\n",
    "- `path` – absolute or relative file path to the image  \n",
    "- `cancer` – binary label where 1 means cancer and 0 means no cancer  \n",
    "\n",
    "The dataset returns a tuple `(image_tensor, label_tensor)` where:\n",
    "\n",
    "- `image_tensor` is an RGB image with an optional torchvision transform already applied  \n",
    "- `label_tensor` is a `LongTensor` with values 0 or 1, suitable for `CrossEntropyLoss`  \n",
    "\n",
    "This generic dataset can be used with all model pipelines (e.g. EfficientNet-B0, ResNet-50) as long as the appropriate transforms are provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Dataset class for CSV-based image loading\n",
    "\n",
    "class CsvImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generic dataset that reads images and binary labels from a CSV file.\n",
    "\n",
    "    Expected columns:\n",
    "      - 'path'   full file path to the image\n",
    "      - 'cancer' 0 or 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        # Read the CSV into a DataFrame and keep it in memory\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Optional torchvision transform pipeline applied to each image\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of samples equals number of rows in the DataFrame\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the row for the given index\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Extract file path and label from the row\n",
    "        img_path = Path(row[\"path\"])\n",
    "        label = int(row[\"cancer\"])\n",
    "\n",
    "        # Load the image from disk and convert to RGB\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Apply transforms if provided\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # CrossEntropyLoss expects labels as LongTensor with class indices\n",
    "        target = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Image transforms (train, validation, test)\n",
    "\n",
    "Both EfficientNet-B0 and ResNet-50 expect images of size 256×256 with ImageNet-style normalization.  \n",
    "We define three transform pipelines:\n",
    "\n",
    "- `train` with light data augmentation  \n",
    "  - resize to 256×256  \n",
    "  - random horizontal flip  \n",
    "  - small random rotation (±10°)  \n",
    "  - slight brightness/contrast jitter  \n",
    "  - convert to tensor  \n",
    "  - normalize with ImageNet mean and standard deviation  \n",
    "\n",
    "- `val` deterministic preprocessing for validation  \n",
    "  - resize to 256×256  \n",
    "  - convert to tensor  \n",
    "  - normalize with ImageNet mean and standard deviation  \n",
    "\n",
    "- `test` identical to `val`, used for final test evaluation  \n",
    "\n",
    "These transforms are shared across all models and datasets to keep preprocessing consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Image transforms (train, validation, test)\n",
    "\n",
    "def get_image_transforms(image_size: int = 256):\n",
    "    \"\"\"\n",
    "    Returns torchvision transform pipelines for train, validation and test.\n",
    "\n",
    "    All pipelines:\n",
    "      - Resize to (image_size, image_size)\n",
    "      - Convert to tensor\n",
    "      - Normalize with ImageNet mean and std\n",
    "\n",
    "    The train pipeline additionally applies light data augmentation\n",
    "    to reduce overfitting.\n",
    "    \"\"\"\n",
    "\n",
    "    imagenet_mean = [0.485, 0.456, 0.406]\n",
    "    imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # Training transform with slightly stronger augmentation\n",
    "    train_transform = T.Compose(\n",
    "        [\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.RandomHorizontalFlip(p=0.5),\n",
    "            T.RandomRotation(degrees=10),\n",
    "            T.ColorJitter(\n",
    "                brightness=0.1,\n",
    "                contrast=0.1,\n",
    "            ),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Validation transform without random augmentation\n",
    "    val_transform = T.Compose(\n",
    "        [\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # For this project validation and test transforms are identical\n",
    "    test_transform = val_transform\n",
    "\n",
    "    return {\n",
    "        \"train\": train_transform,\n",
    "        \"val\": val_transform,\n",
    "        \"test\": test_transform,\n",
    "    }\n",
    "\n",
    "\n",
    "# Create shared transforms dictionary that we will reuse later\n",
    "TRANSFORMS = get_image_transforms(image_size=256)\n",
    "print(\"Defined image transforms for train, val and test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Helper functions for metrics\n",
    "\n",
    "We use helper functions to compute and nicely print standard\n",
    "binary classification metrics:\n",
    "\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1 score  \n",
    "\n",
    "All metrics treat label `1` as the positive (cancer) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Helper functions for metrics\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute accuracy, precision, recall and F1 for binary classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : list or 1D tensor of int\n",
    "        Ground truth labels (0 or 1).\n",
    "    y_pred : list or 1D tensor of int\n",
    "        Predicted labels (0 or 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys: accuracy, precision, recall, f1\n",
    "    \"\"\"\n",
    "    y_true = torch.as_tensor(y_true, dtype=torch.long).cpu().numpy()\n",
    "    y_pred = torch.as_tensor(y_pred, dtype=torch.long).cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=\"binary\",\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_metrics(metrics_dict, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Nicely print a metrics dictionary produced by compute_metrics.\n",
    "    \"\"\"\n",
    "    if prefix:\n",
    "        print(prefix)\n",
    "\n",
    "    print(f\"Accuracy : {metrics_dict['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics_dict['precision']:.4f}\")\n",
    "    print(f\"Recall   : {metrics_dict['recall']:.4f}\")\n",
    "    print(f\"F1 score : {metrics_dict['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Training and evaluation functions\n",
    "\n",
    "To keep all later stages simple, we define two core helpers:\n",
    "\n",
    "- `run_one_epoch`  \n",
    "  Runs one pass over a DataLoader either in training or evaluation mode and\n",
    "  returns the average loss and all predictions/labels for that epoch.\n",
    "\n",
    "- `train_model`  \n",
    "  Wraps the full training loop:\n",
    "  - trains for a given number of epochs  \n",
    "  - evaluates on the validation set after each epoch  \n",
    "  - tracks the best model based on validation recall  \n",
    "  - returns the best model state dict and a history list with one log dictionary per epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Training and evaluation functions\n",
    "\n",
    "def run_one_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run a single epoch on the given dataloader.\n",
    "\n",
    "    If optimizer is provided the model is trained.\n",
    "    If optimizer is None the model is only evaluated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    avg_loss : float\n",
    "    all_labels : list[int]\n",
    "    all_preds  : list[int]\n",
    "    \"\"\"\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    else:\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: logits of shape (batch_size, 2)\n",
    "        logits = model(images)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Convert logits to predicted class indices\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_labels.extend(labels.detach().cpu().tolist())\n",
    "        all_preds.extend(preds.detach().cpu().tolist())\n",
    "\n",
    "        if optimizer is not None:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader.dataset)\n",
    "\n",
    "    # Switch back to eval mode by default\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    return avg_loss, all_labels, all_preds\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device=DEVICE,\n",
    "    stage_name=\"training\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic training loop for binary classification.\n",
    "\n",
    "    Tracks the best model based on validation recall and returns\n",
    "    both the best state dict and a list of per epoch logs.\n",
    "    \"\"\"\n",
    "    best_val_recall = 0.0\n",
    "    best_state_dict = None\n",
    "    history = []\n",
    "\n",
    "    print(f\"Start {stage_name} on device {device} for {num_epochs} epochs.\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        # Training phase\n",
    "        train_loss, train_labels, train_preds = run_one_epoch(\n",
    "            model=model,\n",
    "            dataloader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "        )\n",
    "        train_metrics = compute_metrics(train_labels, train_preds)\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_labels, val_preds = run_one_epoch(\n",
    "            model=model,\n",
    "            dataloader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=None,\n",
    "            device=device,\n",
    "        )\n",
    "        val_metrics = compute_metrics(val_labels, val_preds)\n",
    "\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "        print_metrics(train_metrics, prefix=\"Train metrics:\")\n",
    "\n",
    "        print(f\"\\nVal loss  : {val_loss:.4f}\")\n",
    "        print_metrics(val_metrics, prefix=\"Val metrics:\")\n",
    "\n",
    "        # Store epoch log\n",
    "        epoch_log = {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"train_metrics\": train_metrics,\n",
    "            \"val_metrics\": val_metrics,\n",
    "        }\n",
    "        history.append(epoch_log)\n",
    "\n",
    "        # Model selection based on validation recall\n",
    "        val_recall = val_metrics[\"recall\"]\n",
    "        if val_recall > best_val_recall:\n",
    "            best_val_recall = val_recall\n",
    "            best_state_dict = model.state_dict()\n",
    "            print(\n",
    "                f\"\\nNew best validation recall: {best_val_recall:.4f}. \"\n",
    "                \"Updated best model checkpoint in memory.\"\n",
    "            )\n",
    "\n",
    "    print(f\"\\nFinished {stage_name}. Best validation recall: {best_val_recall:.4f}\")\n",
    "\n",
    "    return best_state_dict, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Function to load EfficientNet-B0 model\n",
    "\n",
    "We create a helper that builds an EfficientNet-B0 model for\n",
    "breast cancer classification and loads pretrained weights from\n",
    "a Hugging Face repository (by default:\n",
    "\n",
    "`keanteng/efficientnet-b0-breast-cancer-classification-0604-2`).\n",
    "\n",
    "The function:\n",
    "\n",
    "- downloads a JSON config (`config.json`) and reads `image_size` and `classes`\n",
    "- creates the EfficientNet-B0 backbone without pretrained ImageNet weights\n",
    "- replaces the classifier head with a linear layer matching the number of classes from the config\n",
    "- loads the weights from the `model.safetensors` file\n",
    "- moves the model to the given device and sets it to eval mode\n",
    "- returns the model, the configured image size, and the list of class names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Function to load EfficientNet-B0 model\n",
    "\n",
    "def load_efficientnet_b0_from_hf(\n",
    "    repo_id: str = \"keanteng/efficientnet-b0-breast-cancer-classification-0604-2\",\n",
    "    config_filename: str = \"config.json\",\n",
    "    weights_filename: str = \"model.safetensors\",\n",
    "    device: torch.device = DEVICE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load EfficientNet-B0 for binary breast cancer classification\n",
    "    from a Hugging Face repository.\n",
    "\n",
    "    The repository is expected to provide:\n",
    "      - a JSON config with keys 'image_size' and 'classes'\n",
    "      - a 'model.safetensors' file with the model weights\n",
    "    \"\"\"\n",
    "    # Download config and read model metadata\n",
    "    config_path = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        filename=config_filename,\n",
    "    )\n",
    "\n",
    "    with open(config_path, \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    image_size = cfg.get(\"image_size\", 256)\n",
    "    class_names = cfg.get(\"classes\", [\"Has_Cancer\", \"Normal\"])\n",
    "\n",
    "    print(\"Image size from config:\", image_size)\n",
    "    print(\"Classes from config:\", class_names)\n",
    "\n",
    "    # Download the weights file\n",
    "    weights_path = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        filename=weights_filename,\n",
    "    )\n",
    "\n",
    "    # Create EfficientNet-B0 architecture without pretrained weights\n",
    "    model = efficientnet_b0(weights=None)\n",
    "\n",
    "    # Replace classifier head with the correct number of output classes\n",
    "    num_features = model.classifier[1].in_features\n",
    "    num_classes = len(class_names)\n",
    "    model.classifier[1] = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    # Load weights from safetensors file\n",
    "    state_dict = safe_load(weights_path)\n",
    "    missing_unexpected = model.load_state_dict(state_dict, strict=True)\n",
    "    print(\"Loaded state dict. Missing/Unexpected keys:\", missing_unexpected)\n",
    "\n",
    "    # Move model to device and set to eval mode by default\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model, image_size, class_names\n",
    "\n",
    "\n",
    "print(\"Utility functions for datasets, transforms, metrics and training have been defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Function to load ResNet50 model\n",
    "\n",
    "We define a small helper to load a ResNet50 model pretrained on ImageNet,\n",
    "adapt it for breast cancer classification, and move it to the selected device.\n",
    "This keeps the rest of the training and evaluation pipeline identical to\n",
    "the EfficientNet setup.\n",
    "\n",
    "The function:\n",
    "\n",
    "- loads a standard ImageNet-pretrained ResNet50 backbone  \n",
    "- replaces the final fully connected layer with a classifier head for the desired number of classes (default: 2)  \n",
    "- moves the model to the requested device and sets it to eval mode  \n",
    "- returns the model, the expected image size (256) and the class names (`[\"Has_Cancer\", \"Normal\"]`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 Function to load ResNet50 model\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "def load_resnet50_base(\n",
    "    num_classes: int = 2,\n",
    "    device: torch.device = DEVICE,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a ResNet50 model pretrained on ImageNet and adapt it\n",
    "    for binary breast cancer classification.\n",
    "\n",
    "    This helper\n",
    "    - loads the standard ImageNet pretrained ResNet50 backbone\n",
    "    - replaces the final fully connected layer with a binary classifier\n",
    "    - moves the model to the requested device\n",
    "    - returns the model, the expected image size and the class names\n",
    "    \"\"\"\n",
    "\n",
    "    # Load ResNet50 with ImageNet pretrained weights\n",
    "    model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "    # Replace final fully connected layer with a binary classifier head\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    # Move to device and set eval mode by default\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Keep same input size as EfficientNet to reuse transforms\n",
    "    image_size = 256\n",
    "    class_names = [\"Has_Cancer\", \"Normal\"]\n",
    "\n",
    "    print(\"ResNet50 base model loaded.\")\n",
    "    print(\"Image size:\", image_size)\n",
    "    print(\"Classes   :\", class_names)\n",
    "\n",
    "    return model, image_size, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "# Part 2: EfficientNet-B0 Pipeline\n",
    "\n",
    "## 4. Stage A: Baseline on RSNA (Eff_Base)\n",
    "\n",
    "4.1 Load EfficientNet-B0 base model (Eff_Base)  \n",
    "4.2 Build RSNA test DataLoader  \n",
    "4.3 Baseline inference on RSNA test set  \n",
    "\n",
    "\n",
    "## 5. Stage B: Fine Tuning on RSNA (Eff_FT1)\n",
    "\n",
    "5.1 Build RSNA train and validation DataLoaders  \n",
    "5.2 Initialize model, optimizer and class-weighted loss for RSNA  \n",
    "5.3 Train EfficientNet on RSNA → Eff_FT1  \n",
    "5.4 Evaluate Eff_FT1 on RSNA test set  \n",
    "\n",
    "\n",
    "## 6. Stage C: Zero-Shot Evaluation on KAU (Eff_FT1)\n",
    "\n",
    "6.1 Build KAU test DataLoader  \n",
    "6.2 Evaluate Eff_FT1 on KAU test set  \n",
    "\n",
    "\n",
    "## 7. Stage D: Fine Tuning on KAU (Eff_FT2)\n",
    "\n",
    "7.1 Build KAU train and validation DataLoaders  \n",
    "7.2 Initialize model, optimizer and class-weighted loss for KAU (starting from Eff_FT1)  \n",
    "7.3 Train EfficientNet on KAU → Eff_FT2  \n",
    "7.4 Evaluate Eff_FT2 on KAU test set  \n",
    "\n",
    "\n",
    "## 8. Stage E: Back-Evaluation on RSNA (Eff_FT2)\n",
    "\n",
    "8.1 Evaluate Eff_FT2 on RSNA test set  \n",
    "8.2 Compare EfficientNet results (Eff_Base vs Eff_FT1 vs Eff_FT2)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stage A: Baseline on RSNA (Eff_Base)\n",
    "\n",
    "### 4.1 Load EfficientNet-B0 base model (Eff_Base) \n",
    "\n",
    "We load the EfficientNet-B0 model from the Hugging Face repository:\n",
    "\n",
    "`keanteng/efficientnet-b0-breast-cancer-classification-0604-2`\n",
    "\n",
    "The function defined in Section 3.5:\n",
    "\n",
    "- downloads the config & weights  \n",
    "- builds the EfficientNet-B0 architecture  \n",
    "- replaces the classifier for binary output  \n",
    "- loads the weights  \n",
    "- returns model + image size + class names  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Load EfficientNet-B0 base model (Eff_Base) \n",
    "\n",
    "base_model, base_image_size, base_class_names = load_efficientnet_b0_from_hf()\n",
    "\n",
    "print(\"\\nBase model loaded successfully.\")\n",
    "print(\"Image size:\", base_image_size)\n",
    "print(\"Classes:\", base_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Build RSNA test DataLoader\n",
    "\n",
    "We now load the RSNA test split that we created earlier in Section 2.  \n",
    "Using our shared utilities:\n",
    "\n",
    "- `CsvImageDataset` → loads images and labels from the CSV file  \n",
    "- `TRANSFORMS[\"test\"]` → deterministic preprocessing for evaluation  \n",
    "- `DataLoader` → batches the data and loads it efficiently from disk using multiple workers  \n",
    "\n",
    "Together with the training/evaluation loop (which moves batches to the selected device), this provides the model with correctly formatted input for inference on the RSNA test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Build RSNA test DataLoader\n",
    "\n",
    "RSNA_TEST_CSV = RSNA_SPLITS_DIR / \"test_split.csv\"\n",
    "\n",
    "rsna_test_dataset = CsvImageDataset(\n",
    "    csv_path=RSNA_TEST_CSV,\n",
    "    transform=TRANSFORMS[\"test\"],\n",
    ")\n",
    "\n",
    "rsna_test_loader = DataLoader(\n",
    "    rsna_test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(f\"RSNA test dataset loaded: {len(rsna_test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Baseline Inference on RSNA Test Set\n",
    "\n",
    "We evaluate the pretrained base model on the RSNA test split.\n",
    "\n",
    "Steps:\n",
    "- forward pass over the test set (no gradient computation)  \n",
    "- get predicted labels  \n",
    "- compute accuracy, precision, recall and F1  \n",
    "\n",
    "This provides the baseline we will later compare against:\n",
    "- Model 1 (RSNA fine-tuning)  \n",
    "- Model 2 (KAU fine-tuning)  \n",
    "- Cross-dataset evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Baseline inference on RSNA test set\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Only evaluation → optimizer=None\n",
    "test_loss, y_true, y_pred = run_one_epoch(\n",
    "    model=base_model,\n",
    "    dataloader=rsna_test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "baseline_metrics = compute_metrics(y_true, y_pred)\n",
    "\n",
    "print(f\"RSNA baseline test loss: {test_loss:.4f}\")\n",
    "print_metrics(baseline_metrics, prefix=\"Baseline metrics on RSNA test set:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stage B: Fine Tuning on RSNA (Eff_FT1)\n",
    "\n",
    "### 5.1 Build RSNA train and validation DataLoaders\n",
    "\n",
    "We now load the RSNA train and validation CSV files that we created in\n",
    "Section 2.\n",
    "\n",
    "We reuse:\n",
    "- `CsvImageDataset` from Section 3.1\n",
    "- `TRANSFORMS[\"train\"]` and `TRANSFORMS[\"val\"]` from Section 3.2\n",
    "\n",
    "The DataLoaders take care of batching, shuffling (for train) and\n",
    "background loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Build RSNA train and validation DataLoaders\n",
    "\n",
    "RSNA_TRAIN_CSV = RSNA_SPLITS_DIR / \"train_split.csv\"\n",
    "RSNA_VAL_CSV   = RSNA_SPLITS_DIR / \"val_split.csv\"\n",
    "\n",
    "rsna_train_dataset = CsvImageDataset(\n",
    "    csv_path=RSNA_TRAIN_CSV,\n",
    "    transform=TRANSFORMS[\"train\"],\n",
    ")\n",
    "\n",
    "rsna_val_dataset = CsvImageDataset(\n",
    "    csv_path=RSNA_VAL_CSV,\n",
    "    transform=TRANSFORMS[\"val\"],\n",
    ")\n",
    "\n",
    "rsna_train_loader = DataLoader(\n",
    "    rsna_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,          # shuffle for training\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "rsna_val_loader = DataLoader(\n",
    "    rsna_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,         # no shuffle for validation\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(f\"RSNA train samples: {len(rsna_train_dataset)}\")\n",
    "print(f\"RSNA val samples  : {len(rsna_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Initialize model, optimizer and class-weighted loss for RSNA  \n",
    "\n",
    "For fine-tuning on RSNA we start again from the same pretrained\n",
    "EfficientNet-B0 checkpoint as in Stage A.\n",
    "\n",
    "Steps:\n",
    "- load EfficientNet-B0 and weights from Hugging Face  \n",
    "- compute class frequencies on the RSNA train split and derive inverse-frequency class weights  \n",
    "- create a class-weighted CrossEntropy loss function using these weights  \n",
    "- create an AdamW optimizer with the global learning rate and weight decay  \n",
    "\n",
    "All layers remain trainable. We do not freeze the backbone in this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Initialize model, optimizer and class-weighted loss for RSNA  \n",
    "\n",
    "# Load EfficientNet B0 from Hugging Face (same checkpoint as in Stage A)\n",
    "m1_model, m1_image_size, m1_class_names = load_efficientnet_b0_from_hf()\n",
    "\n",
    "print(\"\\nModel for RSNA fine tuning initialized.\")\n",
    "print(\"Image size:\", m1_image_size)\n",
    "print(\"Classes   :\", m1_class_names)\n",
    "\n",
    "# Compute class weights from RSNA train split\n",
    "# We access the DataFrame stored inside rsna_train_dataset (created in 5.1).\n",
    "train_labels = rsna_train_dataset.df[\"cancer\"]\n",
    "\n",
    "class_counts = train_labels.value_counts().sort_index()\n",
    "num_classes = class_counts.shape[0]\n",
    "total_samples = class_counts.sum()\n",
    "\n",
    "print(\"\\nClass counts in RSNA train split:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Inverse-frequency style weights:\n",
    "#   weight_c = total_samples / (num_classes * count_c)\n",
    "class_weights = total_samples / (num_classes * class_counts.astype(float))\n",
    "\n",
    "print(\"\\nComputed class weights (before tensor conversion):\")\n",
    "print(class_weights)\n",
    "\n",
    "# Convert to tensor on the correct device\n",
    "class_weights_tensor = torch.tensor(\n",
    "    class_weights.values,\n",
    "    dtype=torch.float32,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(\"\\nClass weights tensor on device:\")\n",
    "print(class_weights_tensor)\n",
    "\n",
    "# Define class-weighted loss function\n",
    "m1_criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# AdamW optimizer with global hyperparameters\n",
    "m1_optimizer = torch.optim.AdamW(\n",
    "    m1_model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# Optional: small sanity check on number of trainable parameters\n",
    "num_trainable = sum(p.numel() for p in m1_model.parameters() if p.requires_grad)\n",
    "print(\"Trainable parameters:\", num_trainable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train EfficientNet on RSNA → Eff_FT1   \n",
    "\n",
    "We now fine tune the model on the RSNA train split and\n",
    "monitor performance on the RSNA validation split.\n",
    "\n",
    "The helper `train_model` from Section 3.4:\n",
    "- runs the training loop for `NUM_EPOCHS_RSNA`\n",
    "- evaluates after each epoch on the validation set\n",
    "- keeps track of the best model based on validation recall\n",
    "- returns the best model weights and a training history\n",
    "\n",
    "We then:\n",
    "- load the best weights into `m1_model`\n",
    "- save the best checkpoint to disk as `model1_rsna_best.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Train EfficientNet on RSNA → Eff_FT1 \n",
    "\n",
    "m1_best_state_dict, m1_history = train_model(\n",
    "    model=m1_model,\n",
    "    train_loader=rsna_train_loader,\n",
    "    val_loader=rsna_val_loader,\n",
    "    criterion=m1_criterion,\n",
    "    optimizer=m1_optimizer,\n",
    "    num_epochs=NUM_EPOCHS_RSNA,\n",
    "    device=DEVICE,\n",
    "    stage_name=\"Fine tuning on RSNA (Model 1)\",\n",
    ")\n",
    "\n",
    "# Load best weights into the model\n",
    "if m1_best_state_dict is not None:\n",
    "    m1_model.load_state_dict(m1_best_state_dict)\n",
    "    print(\"\\nLoaded best validation checkpoint into m1_model.\")\n",
    "\n",
    "# Optionally save the best checkpoint to disk\n",
    "MODEL1_PATH = Path(\"/kaggle/working/model1_rsna_best.pth\")\n",
    "torch.save(m1_model.state_dict(), MODEL1_PATH)\n",
    "print(\"Saved Model 1 (RSNA fine tuned) to:\", MODEL1_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Evaluate Eff_FT1 on RSNA test set\n",
    "\n",
    "Finally we evaluate Model 1 (M1) on the held out RSNA test set.\n",
    "\n",
    "This tells us:\n",
    "- how well the RSNA fine tuned model generalizes to unseen RSNA images\n",
    "- how much it improves compared to the base model from Stage A\n",
    "\n",
    "We reuse:\n",
    "- `rsna_test_loader` from Section 4.2\n",
    "- `run_one_epoch` and `compute_metrics` from Section 3.4 and 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Evaluate Eff_FT1 on RSNA test set\n",
    "\n",
    "m1_test_loss, m1_y_true, m1_y_pred = run_one_epoch(\n",
    "    model=m1_model,\n",
    "    dataloader=rsna_test_loader,\n",
    "    criterion=m1_criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "m1_test_metrics = compute_metrics(m1_y_true, m1_y_pred)\n",
    "\n",
    "print(f\"Model 1 RSNA test loss: {m1_test_loss:.4f}\")\n",
    "print_metrics(m1_test_metrics, prefix=\"Model 1 metrics on RSNA test set:\")\n",
    "\n",
    "# Optional quick comparison to baseline if available\n",
    "if \"baseline_metrics\" in globals():\n",
    "    print(\"\\nQuick comparison to base model (RSNA test):\")\n",
    "    print(f\"Baseline recall: {baseline_metrics['recall']:.4f}\")\n",
    "    print(f\"M1 recall      : {m1_test_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stage C: Zero-Shot Evaluation on KAU (Eff_FT1)\n",
    "\n",
    "### 6.1 Build KAU test DataLoader\n",
    "\n",
    "We now load the KAU test split created in Section 2.4.\n",
    "\n",
    "We reuse:\n",
    "- `CsvImageDataset` for reading images and labels from the CSV file  \n",
    "- `TRANSFORMS[\"test\"]` for deterministic preprocessing  \n",
    "- the global batch size and number of workers from the setup section  \n",
    "\n",
    "This DataLoader provides the KAU test data for zero-shot evaluation of the RSNA fine-tuned model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Build KAU test DataLoader\n",
    "\n",
    "KAU_TEST_CSV = KAU_SPLITS_DIR / \"test_split.csv\"\n",
    "\n",
    "kau_test_dataset = CsvImageDataset(\n",
    "    csv_path=KAU_TEST_CSV,\n",
    "    transform=TRANSFORMS[\"test\"],\n",
    ")\n",
    "\n",
    "kau_test_loader = DataLoader(\n",
    "    kau_test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(f\"KAU test samples: {len(kau_test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Evaluate Eff_FT1 on KAU test set\n",
    "\n",
    "We now evaluate Model 1 (M1), which was fine tuned on RSNA,\n",
    "on the KAU test set.\n",
    "\n",
    "This is a **zero shot** evaluation on KAU:\n",
    "- the model has never seen KAU images during training\n",
    "- any performance drop compared to RSNA indicates domain shift\n",
    "\n",
    "We reuse:\n",
    "- `kau_test_loader` from step 6.1\n",
    "- `run_one_epoch` and `compute_metrics` from the utilities section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Evaluate Eff_FT1 on KAU test set\n",
    "\n",
    "m1_kau_test_loss, m1_kau_y_true, m1_kau_y_pred = run_one_epoch(\n",
    "    model=m1_model,\n",
    "    dataloader=kau_test_loader,\n",
    "    criterion=m1_criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "m1_kau_metrics = compute_metrics(m1_kau_y_true, m1_kau_y_pred)\n",
    "\n",
    "print(f\"Model 1 KAU test loss: {m1_kau_test_loss:.4f}\")\n",
    "print_metrics(m1_kau_metrics, prefix=\"Model 1 metrics on KAU test set (zero shot):\")\n",
    "\n",
    "# Optional quick comparison to RSNA test performance\n",
    "if \"m1_test_metrics\" in globals():\n",
    "    print(\"\\nQuick comparison RSNA vs KAU for Model 1:\")\n",
    "    print(f\"RSNA recall: {m1_test_metrics['recall']:.4f}\")\n",
    "    print(f\"KAU recall : {m1_kau_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stage D: Fine Tuning on KAU (Eff_FT2)\n",
    "\n",
    "### 7.1 Build KAU train and validation DataLoaders\n",
    "\n",
    "We now load the KAU train and validation splits that we saved\n",
    "in Section 2.4.\n",
    "\n",
    "We reuse:\n",
    "- `CsvImageDataset` for reading paths and labels from CSV  \n",
    "- `TRANSFORMS[\"train\"]` and `TRANSFORMS[\"val\"]` for preprocessing  \n",
    "- the global batch size and number of workers  \n",
    "\n",
    "These DataLoaders provide the KAU data for fine-tuning the EfficientNet model (Eff_FT2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Build KAU train and validation DataLoaders\n",
    "\n",
    "KAU_TRAIN_CSV = KAU_SPLITS_DIR / \"train_split.csv\"\n",
    "KAU_VAL_CSV   = KAU_SPLITS_DIR / \"val_split.csv\"\n",
    "\n",
    "kau_train_dataset = CsvImageDataset(\n",
    "    csv_path=KAU_TRAIN_CSV,\n",
    "    transform=TRANSFORMS[\"train\"],\n",
    ")\n",
    "\n",
    "kau_val_dataset = CsvImageDataset(\n",
    "    csv_path=KAU_VAL_CSV,\n",
    "    transform=TRANSFORMS[\"val\"],\n",
    ")\n",
    "\n",
    "kau_train_loader = DataLoader(\n",
    "    kau_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,           # shuffle for training\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "kau_val_loader = DataLoader(\n",
    "    kau_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(f\"KAU train samples: {len(kau_train_dataset)}\")\n",
    "print(f\"KAU val samples  : {len(kau_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Initialize model, optimizer and class-weighted loss for KAU (starting from Eff_FT1)  \n",
    "\n",
    "For KAU fine-tuning we ideally start from the RSNA fine-tuned model (M1).\n",
    "\n",
    "Steps:\n",
    "- create a new EfficientNet-B0 instance with the helper from Section 3  \n",
    "- try to load the weights of Model 1, either from the saved checkpoint (`model1_rsna_best.pth`) or directly from `m1_model` in memory; if neither is available, continue from the base EfficientNet weights  \n",
    "- compute class frequencies on the KAU train split and derive inverse-frequency class weights  \n",
    "- define a class-weighted CrossEntropy loss function using these weights  \n",
    "- create an AdamW optimizer with the global learning rate and weight decay  \n",
    "\n",
    "All layers remain trainable; we do not freeze the backbone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Initialize model, optimizer and class-weighted loss for KAU (starting from Eff_FT1)\n",
    "\n",
    "m2_model, m2_image_size, m2_class_names = load_efficientnet_b0_from_hf()\n",
    "\n",
    "print(\"\\nFresh model instance for KAU fine tuning created.\")\n",
    "print(\"Image size:\", m2_image_size)\n",
    "print(\"Classes   :\", m2_class_names)\n",
    "\n",
    "# Try to load the RSNA fine tuned weights (Model 1)\n",
    "if \"MODEL1_PATH\" in globals() and Path(MODEL1_PATH).exists():\n",
    "    state_dict_m1 = torch.load(MODEL1_PATH, map_location=DEVICE)\n",
    "    m2_model.load_state_dict(state_dict_m1)\n",
    "    print(\"Loaded Model 1 weights from:\", MODEL1_PATH)\n",
    "elif \"m1_model\" in globals():\n",
    "    m2_model.load_state_dict(m1_model.state_dict())\n",
    "    print(\"Loaded Model 1 weights from m1_model in memory.\")\n",
    "else:\n",
    "    print(\n",
    "        \"Warning: could not find Model 1 checkpoint. \"\n",
    "        \"Continuing from base EfficientNet weights.\"\n",
    "    )\n",
    "\n",
    "# Compute class weights from KAU train split\n",
    "kau_train_labels = kau_train_dataset.df[\"cancer\"]\n",
    "\n",
    "kau_class_counts = kau_train_labels.value_counts().sort_index()\n",
    "num_kau_classes = kau_class_counts.shape[0]\n",
    "total_kau_samples = kau_class_counts.sum()\n",
    "\n",
    "print(\"\\nClass counts in KAU train split:\")\n",
    "print(kau_class_counts)\n",
    "\n",
    "# Inverse-frequency style weights:\n",
    "#   weight_c = total_samples / (num_classes * count_c)\n",
    "kau_class_weights = total_kau_samples / (\n",
    "    num_kau_classes * kau_class_counts.astype(float)\n",
    ")\n",
    "\n",
    "print(\"\\nComputed KAU class weights (before tensor conversion):\")\n",
    "print(kau_class_weights)\n",
    "\n",
    "kau_class_weights_tensor = torch.tensor(\n",
    "    kau_class_weights.values,\n",
    "    dtype=torch.float32,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(\"\\nKAU class weights tensor on device:\")\n",
    "print(kau_class_weights_tensor)\n",
    "\n",
    "# Define class-weighted loss function for KAU\n",
    "m2_criterion = nn.CrossEntropyLoss(weight=kau_class_weights_tensor)\n",
    "\n",
    "# AdamW optimizer with global hyperparameters\n",
    "m2_optimizer = torch.optim.AdamW(\n",
    "    m2_model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "num_trainable_m2 = sum(p.numel() for p in m2_model.parameters() if p.requires_grad)\n",
    "print(\"Trainable parameters in M2:\", num_trainable_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Train EfficientNet on KAU → Eff_FT2  \n",
    "\n",
    "We now fine tune the model on the KAU training split and validate\n",
    "on the KAU validation split.\n",
    "\n",
    "The helper `train_model`:\n",
    "- runs the full training loop for `NUM_EPOCHS_KAU`\n",
    "- evaluates after each epoch on the validation set\n",
    "- keeps the checkpoint with the best validation recall\n",
    "- returns the best weights and a training history\n",
    "\n",
    "We then load the best weights into `m2_model` and save the\n",
    "checkpoint as `model2_kau_best.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Train EfficientNet on KAU → Eff_FT2  \n",
    "\n",
    "m2_best_state_dict, m2_history = train_model(\n",
    "    model=m2_model,\n",
    "    train_loader=kau_train_loader,\n",
    "    val_loader=kau_val_loader,\n",
    "    criterion=m2_criterion,\n",
    "    optimizer=m2_optimizer,\n",
    "    num_epochs=NUM_EPOCHS_KAU,\n",
    "    device=DEVICE,\n",
    "    stage_name=\"Fine tuning on KAU (Model 2)\",\n",
    ")\n",
    "\n",
    "# Load best validation checkpoint into the model\n",
    "if m2_best_state_dict is not None:\n",
    "    m2_model.load_state_dict(m2_best_state_dict)\n",
    "    print(\"\\nLoaded best validation checkpoint into m2_model.\")\n",
    "\n",
    "# Save the best KAU fine tuned model to disk\n",
    "MODEL2_PATH = Path(\"/kaggle/working/model2_kau_best.pth\")\n",
    "torch.save(m2_model.state_dict(), MODEL2_PATH)\n",
    "print(\"Saved Model 2 (KAU fine tuned) to:\", MODEL2_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Evaluate Eff_FT2 on KAU test set \n",
    "\n",
    "Finally we evaluate Model 2 (M2) on the held out KAU test set.\n",
    "\n",
    "This shows:\n",
    "- how well the KAU fine tuned model generalizes to unseen KAU images\n",
    "- how much it improves compared to the zero shot performance of M1\n",
    "  from Stage C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.4 Evaluate Eff_FT2 on KAU test set\n",
    "\n",
    "m2_kau_test_loss, m2_kau_y_true, m2_kau_y_pred = run_one_epoch(\n",
    "    model=m2_model,\n",
    "    dataloader=kau_test_loader,\n",
    "    criterion=m2_criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "m2_kau_metrics = compute_metrics(m2_kau_y_true, m2_kau_y_pred)\n",
    "\n",
    "print(f\"Model 2 KAU test loss: {m2_kau_test_loss:.4f}\")\n",
    "print_metrics(m2_kau_metrics, prefix=\"Model 2 metrics on KAU test set:\")\n",
    "\n",
    "# Optional comparison to Model 1 on KAU\n",
    "if \"m1_kau_metrics\" in globals():\n",
    "    print(\"\\nComparison of M1 vs M2 on KAU test set:\")\n",
    "    print(f\"M1 recall: {m1_kau_metrics['recall']:.4f}\")\n",
    "    print(f\"M2 recall: {m2_kau_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Stage E: Back-Evaluation on RSNA (Eff_FT2) \n",
    "\n",
    "### 8.1 Evaluate Eff_FT2 on RSNA test set  \n",
    "\n",
    "We reuse the RSNA test DataLoader from Stage A:\n",
    "\n",
    "- `rsna_test_loader` contains the RSNA test split created in Section 2.2  \n",
    "- preprocessing is identical to all previous evaluations  \n",
    "\n",
    "We evaluate Model 2 (M2) on this test set to see how well\n",
    "the KAU fine-tuned model still performs on RSNA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Evaluate Eff_FT2 on RSNA test set  \n",
    "m2_criterion = nn.CrossEntropyLoss() #ADDED THIS LINE HERE\n",
    "\n",
    "m2_rsna_test_loss, m2_rsna_y_true, m2_rsna_y_pred = run_one_epoch(\n",
    "    model=m2_model,\n",
    "    dataloader=rsna_test_loader,\n",
    "    criterion=m2_criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "m2_rsna_metrics = compute_metrics(m2_rsna_y_true, m2_rsna_y_pred)\n",
    "\n",
    "print(f\"Model 2 RSNA test loss: {m2_rsna_test_loss:.4f}\")\n",
    "print_metrics(m2_rsna_metrics, prefix=\"Model 2 metrics on RSNA test set:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Compare EfficientNet results (Eff_Base vs Eff_FT1 vs Eff_FT2) \n",
    "\n",
    "We now summarise the most important metrics for:\n",
    "\n",
    "- Base model  \n",
    "- Model 1 (RSNA fine tuned)  \n",
    "- Model 2 (KAU fine tuned)  \n",
    "\n",
    "on both datasets:\n",
    "\n",
    "- RSNA test set  \n",
    "- KAU test set  \n",
    "\n",
    "The main focus is on **recall**, because missing cancer cases\n",
    "is the most critical error in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2 Compare EfficientNet results (Eff_Base vs Eff_FT1 vs Eff_FT2) \n",
    "\n",
    "comparison_rows = []\n",
    "\n",
    "# Helper to add a row if metrics exist\n",
    "def add_row(model_name, dataset_name, metrics_dict, loss_value):\n",
    "    comparison_rows.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"loss\": loss_value,\n",
    "            \"accuracy\": metrics_dict[\"accuracy\"],\n",
    "            \"precision\": metrics_dict[\"precision\"],\n",
    "            \"recall\": metrics_dict[\"recall\"],\n",
    "            \"f1\": metrics_dict[\"f1\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Base model on RSNA (Stage A)\n",
    "if \"baseline_metrics\" in globals() and \"test_loss\" in globals():\n",
    "    add_row(\"Base\", \"RSNA\", baseline_metrics, test_loss)\n",
    "\n",
    "# Model 1 on RSNA (Stage B)\n",
    "if \"m1_test_metrics\" in globals() and \"m1_test_loss\" in globals():\n",
    "    add_row(\"M1 (RSNA ft)\", \"RSNA\", m1_test_metrics, m1_test_loss)\n",
    "\n",
    "# Model 1 on KAU (Stage C)\n",
    "if \"m1_kau_metrics\" in globals() and \"m1_kau_test_loss\" in globals():\n",
    "    add_row(\"M1 (RSNA ft)\", \"KAU\", m1_kau_metrics, m1_kau_test_loss)\n",
    "\n",
    "# Model 2 on KAU (Stage D)\n",
    "if \"m2_kau_metrics\" in globals() and \"m2_kau_test_loss\" in globals():\n",
    "    add_row(\"M2 (KAU ft)\", \"KAU\", m2_kau_metrics, m2_kau_test_loss)\n",
    "\n",
    "# Model 2 on RSNA (Stage E)\n",
    "if \"m2_rsna_metrics\" in globals() and \"m2_rsna_test_loss\" in globals():\n",
    "    add_row(\"M2 (KAU ft)\", \"RSNA\", m2_rsna_metrics, m2_rsna_test_loss)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_rows)\n",
    "\n",
    "print(\"\\nSummary of all models on both test sets:\")\n",
    "display(comparison_df.style.format(\n",
    "    {\n",
    "        \"loss\": \"{:.4f}\",\n",
    "        \"accuracy\": \"{:.4f}\",\n",
    "        \"precision\": \"{:.4f}\",\n",
    "        \"recall\": \"{:.4f}\",\n",
    "        \"f1\": \"{:.4f}\",\n",
    "    }\n",
    "))\n",
    "\n",
    "# Optional: small text summary focused on recall\n",
    "if not comparison_df.empty:\n",
    "    print(\"\\nRecall comparison by model and dataset:\")\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        print(\n",
    "            f\"{row['model']} on {row['dataset']}: \"\n",
    "            f\"recall = {row['recall']:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "# Part 3: ResNet-50 Pipeline\n",
    "\n",
    "## 9. Stage A:  Baseline on RSNA (Res_Base)\n",
    "\n",
    "9.1 Load ResNet-50 base model (Res_Base)  \n",
    "9.2 Build RSNA test DataLoader  \n",
    "9.3 Baseline inference on RSNA test set  \n",
    "\n",
    "\n",
    "## 10. Stage B:  Fine Tuning on RSNA (Res_FT1)\n",
    "\n",
    "10.1 Build RSNA train and validation DataLoaders  \n",
    "10.2 Initialize model, optimizer and class-weighted loss for RSNA  \n",
    "10.3 Train ResNet on RSNA → Res_FT1  \n",
    "10.4 Evaluate Res_FT1 on RSNA test set  \n",
    "\n",
    "\n",
    "## 11. Stage C:  Zero-Shot Evaluation on KAU (Res_FT1)\n",
    "\n",
    "11.1 Build KAU test DataLoader  \n",
    "11.2 Evaluate Res_FT1 on KAU test set  \n",
    "\n",
    "\n",
    "## 12. Stage D:  Fine Tuning on KAU (Res_FT2)\n",
    "\n",
    "12.1 Build KAU train and validation DataLoaders  \n",
    "12.2 Initialize model, optimizer and class-weighted loss for KAU (starting from Res_FT1)  \n",
    "12.3 Train ResNet on KAU → Res_FT2  \n",
    "12.4 Evaluate Res_FT2 on KAU test set  \n",
    "\n",
    "\n",
    "## 13. Stage E:  Back-Evaluation on RSNA (Res_FT2)\n",
    "\n",
    "13.1 Evaluate Res_FT2 on RSNA test set  \n",
    "13.2 Compare ResNet results (Res_Base vs Res_FT1 vs Res_FT2)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Stage A:  Baseline on RSNA (Res_Base)\n",
    "\n",
    "### 9.1 Load ResNet-50 base model (Res_Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Load ResNet50 base model (Res_Base)\n",
    "\n",
    "res_base_model, res_base_image_size, res_class_names = load_resnet50_base()\n",
    "\n",
    "print(\"ResNet50 base model ready.\")\n",
    "print(\"Image size:\", res_base_image_size)\n",
    "print(\"Classes   :\", res_class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Build RSNA test DataLoader\n",
    "\n",
    "For the ResNet baseline we evaluate on the same RSNA test split as in Stage 4.  \n",
    "We reuse the shared utilities:\n",
    "\n",
    "- `CsvImageDataset` for CSV-based image loading  \n",
    "- `TRANSFORMS[\"test\"]` for deterministic preprocessing  \n",
    "- `DataLoader` for efficient batching and background loading  \n",
    "\n",
    "This ensures that EfficientNet and ResNet see exactly the same input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.2 Build RSNA test DataLoader\n",
    "\n",
    "RSNA_TEST_CSV = RSNA_SPLITS_DIR / \"test_split.csv\"\n",
    "\n",
    "if not RSNA_TEST_CSV.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"RSNA test CSV not found at {RSNA_TEST_CSV}. \"\n",
    "        \"Please run the RSNA split creation cells in Part 1 / Section 2 first.\"\n",
    "    )\n",
    "\n",
    "rsna_test_dataset = CsvImageDataset(\n",
    "    csv_path=RSNA_TEST_CSV,\n",
    "    transform=TRANSFORMS[\"test\"],\n",
    ")\n",
    "\n",
    "rsna_test_loader = DataLoader(\n",
    "    rsna_test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(f\"RSNA test dataset for ResNet loaded: {len(rsna_test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Baseline inference on RSNA test set\n",
    "\n",
    "We now evaluate the ImageNet pretrained ResNet50 (with a binary classifier head)  \n",
    "on the RSNA test split.\n",
    "\n",
    "Steps:\n",
    "- run a forward pass over the test set without gradient computation  \n",
    "- obtain predicted class indices  \n",
    "- compute accuracy, precision, recall and F1  \n",
    "\n",
    "This gives us the ResNet baseline on RSNA, which we will later compare to:\n",
    "- Res_FT1 (fine tuned on RSNA)  \n",
    "- Res_FT2 (fine tuned on KAU)  \n",
    "- the EfficientNet models from Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.3 Baseline inference on RSNA test set\n",
    "\n",
    "res_base_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Evaluation only → optimizer=None\n",
    "res_base_test_loss, res_base_y_true, res_base_y_pred = run_one_epoch(\n",
    "    model=res_base_model,\n",
    "    dataloader=rsna_test_loader,\n",
    "    criterion=res_base_criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "res_base_metrics = compute_metrics(res_base_y_true, res_base_y_pred)\n",
    "\n",
    "print(f\"ResNet50 RSNA baseline test loss: {res_base_test_loss:.4f}\")\n",
    "print_metrics(\n",
    "    res_base_metrics,\n",
    "    prefix=\"ResNet50 baseline metrics on RSNA test set:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Stage B: Fine Tuning on RSNA (Res_FT1)\n",
    "\n",
    "### 10.1 Build RSNA train and validation DataLoaders\n",
    "\n",
    "For ResNet Stage B we use exactly the same RSNA train and validation\n",
    "splits as in EfficientNet Stage B.\n",
    "\n",
    "We reuse:\n",
    "* `CsvImageDataset` from Section 3.1  \n",
    "* `TRANSFORMS[\"train\"]` and `TRANSFORMS[\"val\"]` from Section 3.2  \n",
    "\n",
    "This keeps the data pipeline identical for EfficientNet and ResNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 Build RSNA train and validation DataLoaders\n",
    "\n",
    "RSNA_TRAIN_CSV = RSNA_SPLITS_DIR / \"train_split.csv\"\n",
    "RSNA_VAL_CSV   = RSNA_SPLITS_DIR / \"val_split.csv\"\n",
    "\n",
    "if (not RSNA_TRAIN_CSV.exists()) or (not RSNA_VAL_CSV.exists()):\n",
    "    raise FileNotFoundError(\n",
    "        \"RSNA train or validation CSV not found. \"\n",
    "        \"Please run the RSNA split creation cells in Part 1.\"\n",
    "    )\n",
    "\n",
    "rsna_train_dataset = CsvImageDataset(\n",
    "    csv_path=RSNA_TRAIN_CSV,\n",
    "    transform=TRANSFORMS[\"train\"],\n",
    ")\n",
    "\n",
    "rsna_val_dataset = CsvImageDataset(\n",
    "    csv_path=RSNA_VAL_CSV,\n",
    "    transform=TRANSFORMS[\"val\"],\n",
    ")\n",
    "\n",
    "rsna_train_loader = DataLoader(\n",
    "    rsna_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "rsna_val_loader = DataLoader(\n",
    "    rsna_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(f\"RSNA train samples: {len(rsna_train_dataset)}\")\n",
    "print(f\"RSNA val samples  : {len(rsna_val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Initialize model, optimizer and class-weighted loss for RSNA  \n",
    "\n",
    "We now prepare the ResNet model for fine tuning on RSNA.\n",
    "\n",
    "Steps:\n",
    "* load a fresh ResNet50 base model with ImageNet weights  \n",
    "* compute class weights from the RSNA train labels  \n",
    "* define a class-weighted CrossEntropy loss  \n",
    "* create an AdamW optimizer with the global learning rate and weight decay  \n",
    "\n",
    "All layers of ResNet stay trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.2 Initialize model, optimizer and class-weighted loss for RSNA  \n",
    "\n",
    "# Load a fresh ResNet50 base model for fine tuning on RSNA\n",
    "res_m1_model, res_m1_image_size, res_m1_class_names = load_resnet50_base()\n",
    "\n",
    "print(\"\\nResNet model for RSNA fine tuning initialized.\")\n",
    "print(\"Image size:\", res_m1_image_size)\n",
    "print(\"Classes   :\", res_m1_class_names)\n",
    "\n",
    "# Compute class weights from RSNA train split\n",
    "rsna_train_labels = rsna_train_dataset.df[\"cancer\"]\n",
    "\n",
    "rsna_class_counts = rsna_train_labels.value_counts().sort_index()\n",
    "rsna_num_classes = rsna_class_counts.shape[0]\n",
    "rsna_total_samples = rsna_class_counts.sum()\n",
    "\n",
    "rsna_class_weights = rsna_total_samples / (rsna_num_classes * rsna_class_counts.astype(float))\n",
    "\n",
    "print(\"\\nClass counts in RSNA train split:\")\n",
    "print(rsna_class_counts)\n",
    "print(\"\\nComputed class weights for RSNA train split:\")\n",
    "print(rsna_class_weights)\n",
    "\n",
    "# Convert to tensor on the correct device\n",
    "res_m1_class_weights_tensor = torch.tensor(\n",
    "    rsna_class_weights.values,\n",
    "    dtype=torch.float32,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# Class-weighted loss function\n",
    "res_m1_criterion = nn.CrossEntropyLoss(weight=res_m1_class_weights_tensor)\n",
    "\n",
    "# AdamW optimizer with global hyperparameters\n",
    "res_m1_optimizer = torch.optim.AdamW(\n",
    "    res_m1_model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# Small sanity check on number of trainable parameters\n",
    "res_m1_num_trainable = sum(\n",
    "    p.numel() for p in res_m1_model.parameters() if p.requires_grad\n",
    ")\n",
    "print(\"Trainable parameters in ResNet50 (Res_FT1):\", res_m1_num_trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Train ResNet on RSNA → Res_FT1\n",
    "\n",
    "We fine tune the ResNet50 model on the RSNA train split and monitor\n",
    "performance on the RSNA validation split.\n",
    "\n",
    "The helper `train_model`:\n",
    "* runs the training loop for `NUM_EPOCHS_RSNA`  \n",
    "* evaluates after each epoch on the validation set  \n",
    "* selects the best model based on validation recall  \n",
    "* returns the best model weights and the training history  \n",
    "\n",
    "We load the best weights into `res_m1_model` and save the checkpoint\n",
    "as `resnet_rsna_ft1_best.pth`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.3 Train ResNet on RSNA → Res_FT1\n",
    "\n",
    "res_m1_best_state_dict, res_m1_history = train_model(\n",
    "    model=res_m1_model,\n",
    "    train_loader=rsna_train_loader,\n",
    "    val_loader=rsna_val_loader,\n",
    "    criterion=res_m1_criterion,\n",
    "    optimizer=res_m1_optimizer,\n",
    "    num_epochs=NUM_EPOCHS_RSNA,\n",
    "    device=DEVICE,\n",
    "    stage_name=\"Fine tuning ResNet50 on RSNA (Res_FT1)\",\n",
    ")\n",
    "\n",
    "# Load best weights into the model\n",
    "if res_m1_best_state_dict is not None:\n",
    "    res_m1_model.load_state_dict(res_m1_best_state_dict)\n",
    "    print(\"\\nLoaded best validation checkpoint into res_m1_model.\")\n",
    "\n",
    "# Save the best checkpoint to disk\n",
    "RES_FT1_MODEL_PATH = Path(\"/kaggle/working/resnet_rsna_ft1_best.pth\")\n",
    "torch.save(res_m1_model.state_dict(), RES_FT1_MODEL_PATH)\n",
    "print(\"Saved ResNet50 RSNA fine tuned model (Res_FT1) to:\", RES_FT1_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Evaluate Res_FT1 on RSNA test set\n",
    "\n",
    "Finally we evaluate the fine tuned ResNet model (Res_FT1) on the held out\n",
    "RSNA test set.\n",
    "\n",
    "This shows:\n",
    "* how well Res_FT1 generalizes to unseen RSNA images  \n",
    "* how much it improves compared to the ResNet base model from Stage A  \n",
    "\n",
    "We reuse:\n",
    "* `rsna_test_loader` from Stage 9.2  \n",
    "* `run_one_epoch` and `compute_metrics` from Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.4 Evaluate Res_FT1 on RSNA test set\n",
    "\n",
    "res_m1_test_loss, res_m1_y_true, res_m1_y_pred = run_one_epoch(\n",
    "    model=res_m1_model,\n",
    "    dataloader=rsna_test_loader,\n",
    "    criterion=res_m1_criterion,\n",
    "    optimizer=None,   # evaluation only\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "res_m1_test_metrics = compute_metrics(res_m1_y_true, res_m1_y_pred)\n",
    "\n",
    "print(f\"Res_FT1 RSNA test loss: {res_m1_test_loss:.4f}\")\n",
    "print_metrics(\n",
    "    res_m1_test_metrics,\n",
    "    prefix=\"Res_FT1 (ResNet50 fine tuned on RSNA) metrics on RSNA test set:\",\n",
    ")\n",
    "\n",
    "# Optional quick comparison to ResNet base model if available\n",
    "if \"res_base_metrics\" in globals():\n",
    "    print(\"\\nQuick comparison to ResNet base model on RSNA test set:\")\n",
    "    print(f\"ResNet base recall: {res_base_metrics['recall']:.4f}\")\n",
    "    print(f\"Res_FT1 recall    : {res_m1_test_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Stage C:  Zero-Shot Evaluation on KAU (Res_FT1)\n",
    "\n",
    "### 11.1 Build KAU test DataLoader\n",
    "\n",
    "For ResNet Stage C we evaluate the RSNA fine tuned model (Res_FT1)\n",
    "on the KAU test split without any additional training.\n",
    "\n",
    "We:\n",
    "* load the KAU test split from the CSV file\n",
    "* use `CsvImageDataset` for image loading\n",
    "* apply `TRANSFORMS[\"test\"]` for deterministic preprocessing\n",
    "\n",
    "This keeps the data pipeline consistent with the EfficientNet KAU stages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.1 Build KAU test DataLoader\n",
    "\n",
    "KAU_TEST_CSV = KAU_SPLITS_DIR / \"test_split.csv\"\n",
    "\n",
    "if not KAU_TEST_CSV.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"KAU test CSV not found at {KAU_TEST_CSV}. \"\n",
    "        \"Please run the KAU split creation cells in Part 1.\"\n",
    "    )\n",
    "\n",
    "kau_test_dataset = CsvImageDataset(\n",
    "    csv_path=KAU_TEST_CSV,\n",
    "    transform=TRANSFORMS[\"test\"],\n",
    ")\n",
    "\n",
    "kau_test_loader = DataLoader(\n",
    "    kau_test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(f\"KAU test samples: {len(kau_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Evaluate Res_FT1 on KAU test set\n",
    "\n",
    "We now perform a zero-shot evaluation of the RSNA fine-tuned ResNet\n",
    "model (Res_FT1) on the KAU test split.\n",
    "\n",
    "Steps:\n",
    "- ensure that `res_m1_model` is available; if necessary, reload it from the saved Res_FT1 checkpoint and fall back to the base ResNet50 weights if no checkpoint is found  \n",
    "- run a forward pass over the KAU test set without gradient computation  \n",
    "- compute loss and standard metrics (accuracy, precision, recall, F1)  \n",
    "\n",
    "This shows how well the RSNA-trained ResNet transfers to the KAU domain\n",
    "without any additional fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.2 Evaluate Res_FT1 on KAU test set\n",
    "\n",
    "# Make sure we have the fine tuned model in memory.\n",
    "# If not, try to reload it from disk.\n",
    "if \"res_m1_model\" not in globals():\n",
    "    print(\"res_m1_model not found in memory, trying to reload from disk...\")\n",
    "    res_m1_model, _, _ = load_resnet50_base()\n",
    "    if \"RES_FT1_MODEL_PATH\" in globals() and RES_FT1_MODEL_PATH.exists():\n",
    "        state_dict = torch.load(RES_FT1_MODEL_PATH, map_location=DEVICE)\n",
    "        res_m1_model.load_state_dict(state_dict)\n",
    "        res_m1_model.to(DEVICE)\n",
    "        res_m1_model.eval()\n",
    "        print(\"Loaded Res_FT1 weights from:\", RES_FT1_MODEL_PATH)\n",
    "    else:\n",
    "        print(\"Warning: Res_FT1 checkpoint not found. Using base ResNet50 weights.\")\n",
    "\n",
    "# For evaluation on KAU we use an unweighted loss\n",
    "res_m1_kau_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "res_m1_kau_loss, res_m1_kau_y_true, res_m1_kau_y_pred = run_one_epoch(\n",
    "    model=res_m1_model,\n",
    "    dataloader=kau_test_loader,\n",
    "    criterion=res_m1_kau_criterion,\n",
    "    optimizer=None,   # evaluation only\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "res_m1_kau_metrics = compute_metrics(res_m1_kau_y_true, res_m1_kau_y_pred)\n",
    "\n",
    "print(f\"Res_FT1 zero shot loss on KAU test set: {res_m1_kau_loss:.4f}\")\n",
    "print_metrics(\n",
    "    res_m1_kau_metrics,\n",
    "    prefix=\"Res_FT1 (ResNet fine tuned on RSNA) metrics on KAU test set:\",\n",
    ")\n",
    "\n",
    "# Optional quick comparison to RSNA performance\n",
    "if \"res_m1_test_metrics\" in globals():\n",
    "    print(\"\\nQuick recall comparison RSNA vs KAU for Res_FT1:\")\n",
    "    print(f\"RSNA test recall: {res_m1_test_metrics['recall']:.4f}\")\n",
    "    print(f\"KAU  test recall: {res_m1_kau_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Stage D:  Fine Tuning on KAU (Res_FT2)\n",
    "\n",
    "### 12.1 Build KAU train and validation DataLoaders\n",
    "\n",
    "For ResNet Stage D we use the same KAU train and validation splits\n",
    "as in EfficientNet Stage D.\n",
    "\n",
    "We reuse:\n",
    "* `CsvImageDataset` for reading paths and labels from CSV  \n",
    "* `TRANSFORMS[\"train\"]` and `TRANSFORMS[\"val\"]` for preprocessing  \n",
    "* the global batch size and number of workers  \n",
    "\n",
    "This keeps the KAU data pipeline identical for EfficientNet and ResNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.1 Build KAU train and validation DataLoaders\n",
    "\n",
    "KAU_TRAIN_CSV = KAU_SPLITS_DIR / \"train_split.csv\"\n",
    "KAU_VAL_CSV   = KAU_SPLITS_DIR / \"val_split.csv\"\n",
    "\n",
    "if (not KAU_TRAIN_CSV.exists()) or (not KAU_VAL_CSV.exists()):\n",
    "    raise FileNotFoundError(\n",
    "        \"KAU train or validation CSV not found. \"\n",
    "        \"Please run the KAU split creation cells in Part 1.\"\n",
    "    )\n",
    "\n",
    "kau_train_dataset = CsvImageDataset(\n",
    "    csv_path=KAU_TRAIN_CSV,\n",
    "    transform=TRANSFORMS[\"train\"],\n",
    ")\n",
    "\n",
    "kau_val_dataset = CsvImageDataset(\n",
    "    csv_path=KAU_VAL_CSV,\n",
    "    transform=TRANSFORMS[\"val\"],\n",
    ")\n",
    "\n",
    "kau_train_loader = DataLoader(\n",
    "    kau_train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "kau_val_loader = DataLoader(\n",
    "    kau_val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "print(f\"KAU train samples: {len(kau_train_dataset)}\")\n",
    "print(f\"KAU val samples  : {len(kau_val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 Initialize model, optimizer and class-weighted loss for KAU (starting from Res_FT1)\n",
    "\n",
    "For KAU fine-tuning we aim to start from the RSNA fine-tuned ResNet model (Res_FT1).\n",
    "\n",
    "Steps:\n",
    "* create a new ResNet50 instance with the helper from Section 3.6  \n",
    "* try to load the Res_FT1 weights from disk or, if available, from `res_m1_model` in memory; if no checkpoint is found, continue from the ImageNet-pretrained ResNet50 weights  \n",
    "* compute class weights from the KAU train labels  \n",
    "* define a class-weighted CrossEntropy loss  \n",
    "* create an AdamW optimizer with the global hyperparameters  \n",
    "\n",
    "All layers stay trainable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.2 Initialize model, optimizer and class-weighted loss for KAU (starting from Res_FT1)\n",
    "\n",
    "# Fresh model instance for KAU fine tuning\n",
    "res_m2_model, res_m2_image_size, res_m2_class_names = load_resnet50_base()\n",
    "\n",
    "print(\"\\nFresh ResNet model instance for KAU fine tuning created.\")\n",
    "print(\"Image size:\", res_m2_image_size)\n",
    "print(\"Classes   :\", res_m2_class_names)\n",
    "\n",
    "# Try to load the RSNA fine tuned weights (Res_FT1)\n",
    "if \"RES_FT1_MODEL_PATH\" in globals() and RES_FT1_MODEL_PATH.exists():\n",
    "    state_dict_res_m1 = torch.load(RES_FT1_MODEL_PATH, map_location=DEVICE)\n",
    "    res_m2_model.load_state_dict(state_dict_res_m1)\n",
    "    print(\"Loaded Res_FT1 weights from:\", RES_FT1_MODEL_PATH)\n",
    "elif \"res_m1_model\" in globals():\n",
    "    res_m2_model.load_state_dict(res_m1_model.state_dict())\n",
    "    print(\"Loaded Res_FT1 weights from res_m1_model in memory.\")\n",
    "else:\n",
    "    print(\"Warning: Res_FT1 weights not found. Using ImageNet pretrained ResNet50.\")\n",
    "\n",
    "# Compute class weights from KAU train split\n",
    "kau_train_labels = kau_train_dataset.df[\"cancer\"]\n",
    "\n",
    "kau_class_counts = kau_train_labels.value_counts().sort_index()\n",
    "kau_num_classes  = kau_class_counts.shape[0]\n",
    "kau_total_samples = kau_class_counts.sum()\n",
    "\n",
    "kau_class_weights = kau_total_samples / (kau_num_classes * kau_class_counts.astype(float))\n",
    "\n",
    "print(\"\\nClass counts in KAU train split:\")\n",
    "print(kau_class_counts)\n",
    "print(\"\\nComputed class weights for KAU train split:\")\n",
    "print(kau_class_weights)\n",
    "\n",
    "# Convert to tensor on the correct device\n",
    "kau_class_weights_tensor = torch.tensor(\n",
    "    kau_class_weights.values,\n",
    "    dtype=torch.float32,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "print(\"\\nKAU class weights tensor on device:\")\n",
    "print(kau_class_weights_tensor)\n",
    "\n",
    "# Class-weighted loss function for KAU\n",
    "res_m2_criterion = nn.CrossEntropyLoss(weight=kau_class_weights_tensor)\n",
    "\n",
    "# AdamW optimizer with global hyperparameters\n",
    "res_m2_optimizer = torch.optim.AdamW(\n",
    "    res_m2_model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "res_m2_num_trainable = sum(\n",
    "    p.numel() for p in res_m2_model.parameters() if p.requires_grad\n",
    ")\n",
    "print(\"Trainable parameters in ResNet50 (Res_FT2):\", res_m2_num_trainable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 Train ResNet on KAU → Res_FT2\n",
    "\n",
    "We now fine tune the ResNet model on the KAU train split and validate\n",
    "on the KAU validation split.\n",
    "\n",
    "The helper `train_model`:\n",
    "* runs the training loop for `NUM_EPOCHS_KAU`  \n",
    "* evaluates after each epoch on the validation set  \n",
    "* keeps the checkpoint with the best validation recall  \n",
    "* returns the best weights and the training history  \n",
    "\n",
    "We load the best weights into `res_m2_model` and save the checkpoint\n",
    "as `resnet_kau_ft2_best.pth`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.3 Train ResNet on KAU → Res_FT2\n",
    "\n",
    "res_m2_best_state_dict, res_m2_history = train_model(\n",
    "    model=res_m2_model,\n",
    "    train_loader=kau_train_loader,\n",
    "    val_loader=kau_val_loader,\n",
    "    criterion=res_m2_criterion,\n",
    "    optimizer=res_m2_optimizer,\n",
    "    num_epochs=NUM_EPOCHS_KAU,\n",
    "    device=DEVICE,\n",
    "    stage_name=\"Fine tuning ResNet50 on KAU (Res_FT2)\",\n",
    ")\n",
    "\n",
    "# Load best validation checkpoint into the model\n",
    "if res_m2_best_state_dict is not None:\n",
    "    res_m2_model.load_state_dict(res_m2_best_state_dict)\n",
    "    print(\"\\nLoaded best validation checkpoint into res_m2_model.\")\n",
    "\n",
    "# Save the best KAU fine tuned ResNet model to disk\n",
    "RES_FT2_MODEL_PATH = Path(\"/kaggle/working/resnet_kau_ft2_best.pth\")\n",
    "torch.save(res_m2_model.state_dict(), RES_FT2_MODEL_PATH)\n",
    "print(\"Saved ResNet50 KAU fine tuned model (Res_FT2) to:\", RES_FT2_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 Evaluate Res_FT2 on KAU test set\n",
    "\n",
    "Finally we evaluate the KAU fine tuned ResNet model (Res_FT2)\n",
    "on the held out KAU test set.\n",
    "\n",
    "This shows:\n",
    "* how well Res_FT2 generalizes to unseen KAU images  \n",
    "* how much it improves compared to the zero shot performance of Res_FT1\n",
    "  from Stage C  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.4 Evaluate Res_FT2 on KAU test set\n",
    "\n",
    "res_m2_kau_test_loss, res_m2_kau_y_true, res_m2_kau_y_pred = run_one_epoch(\n",
    "    model=res_m2_model,\n",
    "    dataloader=kau_test_loader,\n",
    "    criterion=res_m2_criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "res_m2_kau_metrics = compute_metrics(res_m2_kau_y_true, res_m2_kau_y_pred)\n",
    "\n",
    "print(f\"Res_FT2 KAU test loss: {res_m2_kau_test_loss:.4f}\")\n",
    "print_metrics(\n",
    "    res_m2_kau_metrics,\n",
    "    prefix=\"Res_FT2 (ResNet fine tuned on KAU) metrics on KAU test set:\",\n",
    ")\n",
    "\n",
    "# Optional comparison to Res_FT1 zero shot performance on KAU\n",
    "if \"res_m1_kau_metrics\" in globals():\n",
    "    print(\"\\nComparison of Res_FT1 vs Res_FT2 on KAU test set:\")\n",
    "    print(f\"Res_FT1 recall: {res_m1_kau_metrics['recall']:.4f}\")\n",
    "    print(f\"Res_FT2 recall: {res_m2_kau_metrics['recall']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Stage E:  Back-Evaluation on RSNA (Res_FT2)\n",
    "\n",
    "### 13.1 Evaluate Res_FT2 on RSNA test set\n",
    "\n",
    "In this step we evaluate the KAU fine-tuned ResNet model (Res_FT2)\n",
    "on the RSNA test split.\n",
    "\n",
    "Steps:\n",
    "- ensure that `res_m2_model` is available; if necessary, reload it from the saved Res_FT2 checkpoint and fall back to the ImageNet-pretrained ResNet50 if no checkpoint is found  \n",
    "- run inference on the RSNA test loader using an unweighted CrossEntropy loss  \n",
    "- compute accuracy, precision, recall and F1  \n",
    "\n",
    "This back evaluation shows how much performance on RSNA changes after\n",
    "fine-tuning on the KAU domain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.1 Evaluate Res_FT2 on RSNA test set\n",
    "\n",
    "# Make sure we have the KAU fine tuned model in memory.\n",
    "# If not, try to reload it from disk.\n",
    "if \"res_m2_model\" not in globals():\n",
    "    print(\"res_m2_model not found in memory, trying to reload from disk...\")\n",
    "    res_m2_model, _, _ = load_resnet50_base()\n",
    "    if \"RES_FT2_MODEL_PATH\" in globals() and RES_FT2_MODEL_PATH.exists():\n",
    "        state_dict_res_m2 = torch.load(RES_FT2_MODEL_PATH, map_location=DEVICE)\n",
    "        res_m2_model.load_state_dict(state_dict_res_m2)\n",
    "        res_m2_model.to(DEVICE)\n",
    "        res_m2_model.eval()\n",
    "        print(\"Loaded Res_FT2 weights from:\", RES_FT2_MODEL_PATH)\n",
    "    else:\n",
    "        print(\"Warning: Res_FT2 checkpoint not found. Using ImageNet pretrained ResNet50.\")\n",
    "\n",
    "# For cross domain evaluation on RSNA we use an unweighted loss\n",
    "res_m2_rsna_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "res_m2_rsna_loss, res_m2_rsna_y_true, res_m2_rsna_y_pred = run_one_epoch(\n",
    "    model=res_m2_model,\n",
    "    dataloader=rsna_test_loader,\n",
    "    criterion=res_m2_rsna_criterion,\n",
    "    optimizer=None,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "res_m2_rsna_metrics = compute_metrics(res_m2_rsna_y_true, res_m2_rsna_y_pred)\n",
    "\n",
    "print(f\"Res_FT2 RSNA back evaluation loss: {res_m2_rsna_loss:.4f}\")\n",
    "print_metrics(\n",
    "    res_m2_rsna_metrics,\n",
    "    prefix=\"Res_FT2 (ResNet fine tuned on KAU) metrics on RSNA test set:\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Compare ResNet results (Res_Base vs Res_FT1 vs Res_FT2)\n",
    "\n",
    "We now collect the key metrics for all ResNet variants:\n",
    "\n",
    "* Res_Base on RSNA test set  \n",
    "* Res_FT1 on RSNA and KAU test sets  \n",
    "* Res_FT2 on KAU and RSNA test sets  \n",
    "\n",
    "The comparison table helps to understand:\n",
    "\n",
    "* how much RSNA fine tuning improves over the ImageNet baseline  \n",
    "* how well the RSNA trained model transfers to KAU without adaptation  \n",
    "* how KAU fine tuning affects performance on both KAU and RSNA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.2 Compare ResNet results (Res_Base vs Res_FT1 vs Res_FT2)\n",
    "\n",
    "comparison_rows_resnet = []\n",
    "\n",
    "# Helper to add a row only if metrics exist\n",
    "def add_resnet_row(model_name, dataset_name, metrics_dict):\n",
    "    if metrics_dict is None:\n",
    "        return\n",
    "    comparison_rows_resnet.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"accuracy\": metrics_dict[\"accuracy\"],\n",
    "            \"precision\": metrics_dict[\"precision\"],\n",
    "            \"recall\": metrics_dict[\"recall\"],\n",
    "            \"f1\": metrics_dict[\"f1\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Res_Base on RSNA\n",
    "if \"res_base_metrics\" in globals():\n",
    "    add_resnet_row(\"Res_Base\", \"RSNA test\", res_base_metrics)\n",
    "\n",
    "# Res_FT1 on RSNA and KAU\n",
    "if \"res_m1_test_metrics\" in globals():\n",
    "    add_resnet_row(\"Res_FT1\", \"RSNA test\", res_m1_test_metrics)\n",
    "\n",
    "if \"res_m1_kau_metrics\" in globals():\n",
    "    add_resnet_row(\"Res_FT1\", \"KAU test\", res_m1_kau_metrics)\n",
    "\n",
    "# Res_FT2 on KAU and RSNA\n",
    "if \"res_m2_kau_metrics\" in globals():\n",
    "    add_resnet_row(\"Res_FT2\", \"KAU test\", res_m2_kau_metrics)\n",
    "\n",
    "if \"res_m2_rsna_metrics\" in globals():\n",
    "    add_resnet_row(\"Res_FT2\", \"RSNA test\", res_m2_rsna_metrics)\n",
    "\n",
    "if not comparison_rows_resnet:\n",
    "    print(\"No ResNet metrics found. Please run Stages A to E first.\")\n",
    "else:\n",
    "    resnet_comparison_df = pd.DataFrame(comparison_rows_resnet)\n",
    "    display(resnet_comparison_df.sort_values([\"model\", \"dataset\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------\n",
    "# Part 4: Final Cross-Model Comparison\n",
    "\n",
    "## 14. Overall Comparison\n",
    "\n",
    "14.1 Combined metric table (Eff_FT1, Eff_FT2, Res_FT1, Res_FT2 on RSNA + KAU)  \n",
    "14.2 Line plots for EfficientNet-B0 and ResNet-50                                    \n",
    "14.3 Interpretation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Overall Comparison\n",
    "\n",
    "### 14.1 Combined metric table (EfficientNet vs ResNet)\n",
    "\n",
    "We now combine the key metrics from:\n",
    "\n",
    "- EfficientNet models (Eff_Base, Eff_FT1, Eff_FT2)  \n",
    "- ResNet models (Res_Base, Res_FT1, Res_FT2)  \n",
    "\n",
    "on both test sets (RSNA and KAU).\n",
    "\n",
    "This table shows accuracy, precision, recall and F1 side by side for\n",
    "both backbones and all stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.1 Combined metric table (EfficientNet vs ResNet)\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# Helper to add a row\n",
    "def add_combined_row(backbone, model_name, dataset_name, metrics_dict, loss_value=None):\n",
    "    all_rows.append(\n",
    "        {\n",
    "            \"backbone\": backbone,\n",
    "            \"model\": model_name,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"loss\": loss_value,\n",
    "            \"accuracy\": metrics_dict[\"accuracy\"],\n",
    "            \"precision\": metrics_dict[\"precision\"],\n",
    "            \"recall\": metrics_dict[\"recall\"],\n",
    "            \"f1\": metrics_dict[\"f1\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# EfficientNet entries\n",
    "# -------------------------\n",
    "if \"comparison_df\" in globals():\n",
    "    # reuse the already computed EfficientNet table\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        add_combined_row(\n",
    "            backbone=\"EfficientNet-B0\",\n",
    "            model_name=row[\"model\"],\n",
    "            dataset_name=row[\"dataset\"],\n",
    "            metrics_dict={\n",
    "                \"accuracy\": row[\"accuracy\"],\n",
    "                \"precision\": row[\"precision\"],\n",
    "                \"recall\": row[\"recall\"],\n",
    "                \"f1\": row[\"f1\"],\n",
    "            },\n",
    "            loss_value=row[\"loss\"],\n",
    "        )\n",
    "else:\n",
    "    # fallback: try to add rows directly from individual metrics\n",
    "    if \"baseline_metrics\" in globals() and \"test_loss\" in globals():\n",
    "        add_combined_row(\"EfficientNet-B0\", \"Base\", \"RSNA test\",\n",
    "                         baseline_metrics, test_loss)\n",
    "    if \"m1_test_metrics\" in globals() and \"m1_test_loss\" in globals():\n",
    "        add_combined_row(\"EfficientNet-B0\", \"M1 (RSNA ft)\", \"RSNA test\",\n",
    "                         m1_test_metrics, m1_test_loss)\n",
    "    if \"m1_kau_metrics\" in globals() and \"m1_kau_test_loss\" in globals():\n",
    "        add_combined_row(\"EfficientNet-B0\", \"M1 (RSNA ft)\", \"KAU test\",\n",
    "                         m1_kau_metrics, m1_kau_test_loss)\n",
    "    if \"m2_kau_metrics\" in globals() and \"m2_kau_test_loss\" in globals():\n",
    "        add_combined_row(\"EfficientNet-B0\", \"M2 (KAU ft)\", \"KAU test\",\n",
    "                         m2_kau_metrics, m2_kau_test_loss)\n",
    "    if \"m2_rsna_metrics\" in globals() and \"m2_rsna_test_loss\" in globals():\n",
    "        add_combined_row(\"EfficientNet-B0\", \"M2 (KAU ft)\", \"RSNA test\",\n",
    "                         m2_rsna_metrics, m2_rsna_test_loss)\n",
    "\n",
    "# -------------------------\n",
    "# ResNet entries\n",
    "# -------------------------\n",
    "if \"resnet_comparison_df\" in globals():\n",
    "    for _, row in resnet_comparison_df.iterrows():\n",
    "        add_combined_row(\n",
    "            backbone=\"ResNet-50\",\n",
    "            model_name=row[\"model\"],\n",
    "            dataset_name=row[\"dataset\"],\n",
    "            metrics_dict={\n",
    "                \"accuracy\": row[\"accuracy\"],\n",
    "                \"precision\": row[\"precision\"],\n",
    "                \"recall\": row[\"recall\"],\n",
    "                \"f1\": row[\"f1\"],\n",
    "            },\n",
    "            loss_value=row.get(\"loss\", None),\n",
    "        )\n",
    "else:\n",
    "    # fallback: add rows from individual ResNet metrics if available\n",
    "    if \"res_base_metrics\" in globals():\n",
    "        add_combined_row(\"ResNet-50\", \"Res_Base\", \"RSNA test\",\n",
    "                         res_base_metrics, None)\n",
    "    if \"res_m1_test_metrics\" in globals():\n",
    "        add_combined_row(\"ResNet-50\", \"Res_FT1\", \"RSNA test\",\n",
    "                         res_m1_test_metrics, None)\n",
    "    if \"res_m1_kau_metrics\" in globals():\n",
    "        add_combined_row(\"ResNet-50\", \"Res_FT1\", \"KAU test\",\n",
    "                         res_m1_kau_metrics, None)\n",
    "    if \"res_m2_kau_metrics\" in globals():\n",
    "        add_combined_row(\"ResNet-50\", \"Res_FT2\", \"KAU test\",\n",
    "                         res_m2_kau_metrics, None)\n",
    "    if \"res_m2_rsna_metrics\" in globals():\n",
    "        add_combined_row(\"ResNet-50\", \"Res_FT2\", \"RSNA test\",\n",
    "                         res_m2_rsna_metrics, None)\n",
    "\n",
    "# Build final DataFrame\n",
    "combined_df = pd.DataFrame(all_rows)\n",
    "\n",
    "if combined_df.empty:\n",
    "    print(\"No metrics found. Please run Parts 2 and 3 before Part 4.\")\n",
    "else:\n",
    "    print(\"Combined EfficientNet vs ResNet comparison:\")\n",
    "    display(\n",
    "        combined_df\n",
    "        .sort_values([\"dataset\", \"backbone\", \"model\"])\n",
    "        .reset_index(drop=True)\n",
    "        .style.format(\n",
    "            {\n",
    "                \"loss\": \"{:.4f}\",\n",
    "                \"accuracy\": \"{:.4f}\",\n",
    "                \"precision\": \"{:.4f}\",\n",
    "                \"recall\": \"{:.4f}\",\n",
    "                \"f1\": \"{:.4f}\",\n",
    "            },\n",
    "            na_rep=\"–\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"\\nRecall comparison by backbone, model and dataset:\")\n",
    "    for _, row in combined_df.sort_values([\"dataset\", \"backbone\", \"model\"]).iterrows():\n",
    "        print(\n",
    "            f\"{row['backbone']} {row['model']} on {row['dataset']}: \"\n",
    "            f\"recall = {row['recall']:.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2 Line plots for EfficientNet-B0 and ResNet-50\n",
    "\n",
    "To visualise the overall behaviour of both backbones, we create two\n",
    "line plots that summarise **accuracy** and **recall** for all stages:\n",
    "\n",
    "- **EfficientNet-B0:**  \n",
    "  - EffNet Base on RSNA  \n",
    "  - EffNet M1 (RSNA fine tuned) on RSNA and KAU  \n",
    "  - EffNet M2 (KAU fine tuned) on KAU and RSNA  \n",
    "\n",
    "- **ResNet-50:**  \n",
    "  - ResNet Base on RSNA  \n",
    "  - Res_FT1 (RSNA fine tuned) on RSNA and KAU  \n",
    "  - Res_FT2 (KAU fine tuned) on KAU and RSNA  \n",
    "\n",
    "The plots reuse the metric dictionaries computed earlier\n",
    "(e.g. `baseline_metrics`, `m1_test_metrics`, `m1_kau_metrics`, …).\n",
    "If some metrics are not available because a previous stage was not run,\n",
    "the corresponding points are simply skipped.\n",
    "\n",
    "This provides a compact, visual comparison of how accuracy and recall\n",
    "change across datasets and fine-tuning stages for each backbone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14.2 Line plots for EfficientNet-B0 and ResNet-50 (accuracy & recall)\n",
    "def build_metric_series(pairs):\n",
    "    \"\"\"\n",
    "    Helper function to build label, accuracy, and recall lists from \n",
    "    a list of (label, variable-name) tuples.\n",
    "    Skips entries whose metric variable does not exist.\n",
    "    \"\"\"\n",
    "    labels, acc, rec = [], [], []\n",
    "    for label, var_name in pairs:\n",
    "        if var_name in globals():\n",
    "            m = globals()[var_name]\n",
    "            labels.append(label)\n",
    "            acc.append(m[\"accuracy\"])\n",
    "            rec.append(m[\"recall\"])\n",
    "    return labels, acc, rec\n",
    "\n",
    "# -----------------------------\n",
    "# EfficientNet-B0\n",
    "# -----------------------------\n",
    "eff_pairs = [\n",
    "    (\"EffNet Base/RSNA\", \"baseline_metrics\"),   # Eff_Base on RSNA\n",
    "    (\"EffNet M1/RSNA\",  \"m1_test_metrics\"),     # Eff_FT1 on RSNA\n",
    "    (\"EffNet M1/KAU\",   \"m1_kau_metrics\"),      # Eff_FT1 on KAU (zero shot)\n",
    "    (\"EffNet M2/KAU\",   \"m2_kau_metrics\"),      # Eff_FT2 on KAU\n",
    "    (\"EffNet M2/RSNA\",  \"m2_rsna_metrics\"),     # Eff_FT2 on RSNA (back eval)\n",
    "]\n",
    "\n",
    "eff_labels, eff_acc, eff_rec = build_metric_series(eff_pairs)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(eff_labels, eff_acc, marker=\"o\", linestyle=\"-\", label=\"accuracy\")\n",
    "plt.plot(eff_labels, eff_rec, marker=\"o\", linestyle=\"-\", label=\"recall\")\n",
    "plt.title(\"EfficientNet-B0\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# ResNet-50\n",
    "# -----------------------------\n",
    "res_pairs = [\n",
    "    (\"ResNet Base/RSNA\",  \"res_base_metrics\"),   # Res_Base on RSNA\n",
    "    (\"ResNet FT1/RSNA\",   \"res_m1_test_metrics\"),# Res_FT1 on RSNA\n",
    "    (\"ResNet FT1/KAU\",    \"res_m1_kau_metrics\"), # Res_FT1 on KAU\n",
    "    (\"ResNet FT2/KAU\",    \"res_m2_kau_metrics\"), # Res_FT2 on KAU\n",
    "    (\"ResNet FT2/RSNA\",   \"res_m2_rsna_metrics\"),# Res_FT2 on RSNA\n",
    "]\n",
    "\n",
    "res_labels, res_acc, res_rec = build_metric_series(res_pairs)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(res_labels, res_acc, marker=\"o\", linestyle=\"-\", label=\"accuracy\")\n",
    "plt.plot(res_labels, res_rec, marker=\"o\", linestyle=\"-\", label=\"recall\")\n",
    "plt.title(\"ResNet-50\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3 Interpretation of Results\n",
    "\n",
    "EfficientNet-BO\n",
    "EffNet Base scored a good recall, but simultaneously a bad accuracy. The high recall value implies that the model performed rather well when it comes to false negatives, meaning EffNet Base had a tendency to not qualify cancerous images as “no-cancer”. But, since the accuracy was very low, we can assume the model qualified most images as cancerous, which relativizes the high recall.\n",
    "Feeding the model with RSNA data and fine-tuning it to EffNet M1 improved accuracy dramatically, but lowered recall too. This is most likely due to dataset problems. In oncology, tumors do not necessarily have to be malignant, they can be benign too. Since the ultimate goal for oncological radiology is to recognize malignant tumors from images, most available datasets categorize benign tumors as “no-cancer”, because they are not harmful. The RSNA dataset is one of these datasets, meaning there are images in the dataset classified as “no-cancer”, even though the patients have a tumor.\n",
    "Recognizing the difference between a benign and a malignant tumor from an image is very hard to impossible. In practice, it can be necessary to extract tissue and analyze it to make sure what kind of tumor a patient has. Model EffNet M1 demonstrates this problem very well. Even though it scores a high accuracy, this is most likely due to the fact, that most of the images in the RSNA dataset (~98%) are classified as “no-cancer”, which means any model classifying most images as “no-cancer” will score high accuracy. The low recall value suggests that the model learned to classify tumorous images as “no-cancer”, because benign cancer is classified as such in the dataset, and the model was unable to tell the difference between benign and malignant tumors.\n",
    "The good performance after fine-tuning with the KAU dataset (EffNet M2), which is structured differently (here we could define ourselves, that only non-tumorous images are to be classified as “no-cancer”) strengthens the theory from above. Now, all tumorous images are classified as “cancer”, leading to improvement in accuracy and strong improvement for recall. This suggests that the model is now good at telling the difference between tumorous and non-tumorous images.\n",
    "Unfortunately, after re-evaluating model EffNet M2 with the RSNA dataset, we can see that the model’s accuracy on RSNA data declined. Still, recall improved compared to EffNet M1, meaning the model tends to forget, but it is no devastating loss in performance.\n",
    "ResNet-50\n",
    "The results for the ResNet-50 models are similar to the EfficientNet-B0 models. The only big difference stems from the base model. Here, the base model already has a similar, but slightly worse, performance than the first fine-tuned version. Accuracy is already high and recall low, suggesting the model classified most images as “no-cancer”. It seems The ResNet-50 base model differs here from the EfficientNet-B0 base model, by classifying most images in the same class too, but for the ResNet-50 base model this class was “no-cancer”, while for the EfficientNet-B0 base model it was “cancer”.\n",
    "Worth mentioning is the spectacular good performance of model ResNet FT2, which was already fine-tuned on KAU data. This model not only scores almost perfect accuracy, but recall too, making it by far the best model of this project."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 4629629,
     "sourceId": 39272,
     "sourceType": "competition"
    },
    {
     "datasetId": 902873,
     "sourceId": 1658282,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2688773,
     "sourceId": 4619402,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6012087,
     "sourceId": 9808001,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7034957,
     "sourceId": 11256609,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
